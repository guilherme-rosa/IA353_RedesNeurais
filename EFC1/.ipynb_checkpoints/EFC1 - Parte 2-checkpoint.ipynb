{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios de Fixação de Conceitos 1 - Parte 2\n",
    "\n",
    "### Índice\n",
    "- [Definição do problema na Questão 2](#definicao_problema)\n",
    "- [*Dataset*: consideraçõs e análise](#dataset_consideracoes_analise)\n",
    "    - [Estrutura do *dataset*](#estrutura_dataset)\n",
    "    - [Distribuição de frequências em função das classes (Histograma)](#dist_frequencias_histograma)\n",
    "    - [Visualização de imagens de dígitos manuscritos](#visualizacao_imagens)\n",
    "- [Conjuntos de treinamento e validação](#conjunto_treinamento_validacao)\n",
    "    - [Validação cruzada](#validacao_cruzada)\n",
    "    - [Dados balanceados e representativos](#dados_balanceados_representativos)\n",
    "- [Questão 2 - Classificador não-linear mas linear nos parâmetros ajustáveis](#modelo_naolinear)\n",
    "    - [Máquina de Aprendizado Extremo - Apresentação da arquitetura](#modelo_elm)\n",
    "    - [Máquina de Aprendizado Extremo - Formulação matemática](#modelo_elm_mat)\n",
    "    - [Considerações para utilizar o modelo de regressão como classificador:](#consideracoes)\n",
    "    - [Parâmetros de desempenho](#param_desempenho)\n",
    "- [Questão 2 - Resolução do problema](#resolucao)\n",
    "    - [Especificações e construção da ELM](#build_elm)\n",
    "    - [Etapa de treinamento e validação - Busca inicial](#busca_inicial)\n",
    "        - [Treinamento e validação](#A1)\n",
    "        - [Melhores coeficientes de regularização obtidos](#A2)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação considerando o erro quadrático médio](#A3)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de classificação correta](#A4)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de erro de classificação](#A5)\n",
    "    - [Etapa de treinamento e validação - Busca refinada considerando o erro quadrático médio](#busca_refinada_MSE)\n",
    "        - [Treinamento e validação](#B1)\n",
    "        - [Melhor coeficiente de regularização obtido](#B2)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação considerando o erro quadrático médio](#B3)\n",
    "    - [Etapa de treinamento e validação - Busca refinada considerando o erro de classificação](#busca_refinada_CE)\n",
    "        - [Treinamento e validação](#C1)\n",
    "        - [Melhor coeficiente de regularização obtido](#C2)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de classificação correta](#C3)\n",
    "        - [Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de erro de classificação](#C4)\n",
    "    - [Etapa de teste](#teste)\n",
    "        - [Treinamento e teste](#D1)\n",
    "        - [Matriz de Confusão](#D2)\n",
    "        - [Matriz de parâmetros](#D3)\n",
    "        - [Gráficos de calor para os parâmetros de cada um dos 10 classificadores lineares](#D4)\n",
    "        - [Exemplos de dígitos classificados incorretamente](#D5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_categorical(y_onehot):\n",
    "    aux = y_onehot.argmax()\n",
    "    if aux < 9:\n",
    "        return aux + 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(y_categorical, titleText, ymax, step):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    \n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.xticks(range(0,10))\n",
    "    plt.yticks(range(0, ymax, step))\n",
    "\n",
    "    plt.title(titleText)\n",
    "    #plt.grid(True, axis='y')\n",
    "\n",
    "    a = plt.hist(y_categorical, range=(-0.5, 9.5), bins=20, align='left', color='royalblue');\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit_images(X, Y_categorical, titlesText, Nimgs=5):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    i = rn.randint(0, X.shape[0])\n",
    "\n",
    "    for index, (image, label) in enumerate(zip(X[i:i+Nimgs], Y_categorical[i:i+Nimgs])):\n",
    "        plt.subplot(1, Nimgs, index + 1)\n",
    "        X_image = np.transpose(np.reshape(image, (28, 28)))\n",
    "        plt.imshow(X_image, cmap='gray')\n",
    "        plt.title(titlesText + f'{label}\\n', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../EFC1/dataset/'\n",
    "\n",
    "data = scipy.io.loadmat(path + 'data.mat')\n",
    "test = scipy.io.loadmat(path + 'test.mat')\n",
    "\n",
    "X = data['X'] \n",
    "Y = data['S'] \n",
    "\n",
    "Xtest = test['Xt']\n",
    "Ytest = test['St']\n",
    "\n",
    "Y_categorical = np.array(tuple(map(onehot_to_categorical, Y)))\n",
    "Ytest_categorical = np.array(tuple(map(onehot_to_categorical, Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "<a id=\"definicao_problema\"></a>\n",
    "### Definição do problema na Questão 2\n",
    "\n",
    "- O objetivo deste exercício consiste em sintetizar modelos não-lineares mas lineares nos parâmetros ajustáveis para classificação de padrões. É implementado um classificador baseado em Máquinas de Aprendizado Extremo (ELM).\n",
    "- É utilizado o famoso *dataset* de imagens de dígitos manuscritos [MNIST](http://yann.lecun.com/exdb/mnist/), o qual contém 60.000 amostras para treinamento e 10.000 amostras para teste.\n",
    "- Cada imagem de entrada contém 784 pixels (no intervalo [0, 255], correspondente a níveis de cinza), visto que a dimensão de cada uma delas é de 28x28 pixels.\n",
    "- O problema de classificação investigado é do tipo multi-classe (10 classes), sendo que cada classe representa um dígito de 0 a 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "<a id=\"dataset_consideracoes_analise\"></a>\n",
    "### *Dataset*: Considerações e Análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"estrutura_dataset\"></a>\n",
    "- **Estrutura do** ***dataset*** **:**\n",
    "    - Os dados de treinamento estão contidos nas matrizes $X$ e $Y$.\n",
    "    \n",
    "    - Matriz $X$:\n",
    "        - Cada linha representa uma amostra de entrada (imagem).\n",
    "        - Cada coluna contém um pixel da amostra de entrada.\n",
    "        - Os valores de cada pixel foram normalizados de modo a apresentar valores no intervalo [0,1].\n",
    "        - A dimensão da matriz $X$ é de 60.000x784 (Temos 60.000 amostras cada uma com 784 pixels).\n",
    "        \n",
    "    - Matriz $Y$:\n",
    "        - Cada linha representa a saída desejada (e conhecida) para cada uma das amostras de entrada.\n",
    "        - Cada saída está na representação *one-hot encoding*, isto é, só existe um elemento não nulo responsável por indicar a classe a qual a amostra pertence. Um exemplo dessa representação é dada durante a execução do código.\n",
    "        - Cada coluna representa uma classe:\n",
    "            - Colunas 0 a 8 representam as classes referentes aos dígitos 1 a 9, respectivamente.\n",
    "            - Coluna 9 representa a classe referente ao dígito 0.\n",
    "    \n",
    "    - As matrizes $X_{test}$ e $Y_{test}$ do conjunto de teste possuem as mesmas características acima, mas com as seguintes dimensões:\n",
    "        - A dimensão da matriz $X_{test}$ é de 10.000x784 (Temos 10.000 amostras cada uma com 784 pixels)\n",
    "        - A dimensão da matriz $Y_{test}$ é de 10.000x10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dimensão da matriz X: {X.shape}')\n",
    "print(f'Dimensão da matriz Y: {Y.shape}')\n",
    "print('--------------------------------------')\n",
    "print(f'Dimensão da matriz Xtest: {Xtest.shape}')\n",
    "print(f'Dimensão da matriz Ytest: {Ytest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = rn.randint(0, Y.shape[0])\n",
    "n2 = rn.randint(0, Ytest.shape[0])\n",
    "\n",
    "print('Exemplo do conjunto de treinamento:')\n",
    "print(f'Saída na representação one-hot encoding: {Y[n1]}')\n",
    "print(f'Saída na representação categórica: {Y_categorical[n1]}')\n",
    "\n",
    "print('--------------------------------------------------------------')\n",
    "\n",
    "print('Exemplo do conjunto de teste:')\n",
    "print(f'Saída na representação one-hot encoding: {Ytest[n2]}')\n",
    "print(f'Saída na representação categórica: {Ytest_categorical[n2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dist_frequencias_histograma\"></a>\n",
    "- **Distribuição de frequências em função das classes (Histograma)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(Y_categorical, titleText='Distribuição de frequências para os dados de treinamento', ymax=10000, step=1000);\n",
    "plot_hist(Ytest_categorical, titleText='Distribuição de frequências para os dados de teste', ymax=1200, step=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizacao_imagens\"></a>\n",
    "- **Visualização de imagens de dígitos manuscritos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit_images(X, Y_categorical, titlesText='Dado de treinamento: ', Nimgs=5)\n",
    "plot_digit_images(Xtest, Ytest_categorical, titlesText='Dado de teste: ', Nimgs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "<a id=\"conjunto_treinamento_validacao\"></a>\n",
    "### Conjuntos de treinamento e validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validacao_cruzada\"></a>\n",
    "- **Validação cruzada**\n",
    "    - Para aumentar a **capacidade de generalização** do modelo, é utilizado a estratégia de validação cruzada conhecida por ***holdout***, em que dividimos as amostras de treinamento da seguinte forma:\n",
    "        - Conjunto de treinamento: p% das amostras são utilizadas para treinar o modelo, de modo a produzir um classificador.\n",
    "        - Conjunto de validação: (1-p)% das amostras são utilizadas para validar o modelo gerado, isto é, são utilizadas na etapa de análise de desempenho.\n",
    "        - Nesta atividade, 80% das amostras de {$X$, $Y$} formam o conjunto de treinamento e 20% formam o conjunto de validação, como pode ser verificado na execução a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dimensão da matriz Xtrain: {Xtrain.shape}')\n",
    "print(f'Dimensão da matriz Ytrain: {Ytrain.shape}')\n",
    "print('--------------------------------------')\n",
    "print(f'Dimensão da matriz Xval: {Xval.shape}')\n",
    "print(f'Dimensão da matriz Yval: {Yval.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dados_balanceados_representativos\"></a>\n",
    "- **Dados balanceados e representativos**\n",
    "    - Uma importante característica que devemos manter nos dois novos conjuntos é o **balanceamento entre as classes**, para que os dados utilizados tanto no conjunto de treinamento quanto no de validação sejam bastante **representativos** do problema.\n",
    "    - O objetivo desta etapa é produzir modelos pouco **enviesados**.\n",
    "    - Deste modo, podemos observar as distribuições de frequência dos dois conjuntos para investigar a proporção de amostras de cada uma das classes nos dois conjuntos citados.\n",
    "    - Como pode ser observado nos resultados abaixo, a proporção de dados por classe em ambos os conjuntos está em um valor adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_categorical = np.array(tuple(map(onehot_to_categorical, Ytrain)))\n",
    "Yval_categorical = np.array(tuple(map(onehot_to_categorical, Yval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_train = plot_hist(Ytrain_categorical, titleText='Distribuição de frequências para os dados de treinamento', ymax=10000, step=1000)\n",
    "\n",
    "aux = aux_train[0]\n",
    "aux = aux[1:len(aux):2]\n",
    "aux = aux*100/Xtrain.shape[0]\n",
    "print('Representação das classes no conjunto de treinamento:')\n",
    "for i in range(len(aux)):\n",
    "    print(f'Classe {i}:  {round(aux[i],2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_val = plot_hist(Yval_categorical, titleText='Distribuição de frequências para os dados de validação', ymax=1500, step=100);\n",
    "\n",
    "aux = aux_val[0]\n",
    "aux = aux[1:len(aux):2]\n",
    "aux = aux*100/Xval.shape[0]\n",
    "print('Representação das classes no conjunto de treinamento:')\n",
    "for i in range(len(aux)):\n",
    "    print(f'Classe {i}:  {round(aux[i],2)}%', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "<a id=\"modelo_naolinear\"></a>\n",
    "### Questão 2 - Classificador não-linear mas linear nos parâmetros ajustáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modelo_elm\"></a>\n",
    "- **Máquina de Aprendizado Extremo (ELM) - Apresentação da arquitetura**\n",
    "    - A Figura 1 apresenta a estrutura de uma rede neural do tipo *fully-connected* com uma camada intermediária.\n",
    "<img src=imagens/rede_fully-connected.PNG> </img>\n",
    "    - Resumidamente, a Máquina de Aprendizado Extremo é um tipo de rede neural *fully-connected* com as seguintes características:\n",
    "        - Camada de entrada: \n",
    "            - A função é passar as amostras de entrada para os neurônios da camada intermediária (não há nenhum processamento).\n",
    "        - Camada intermediária: \n",
    "            - A função é realizar uma transformação não-linear nos dados de entrada.\n",
    "            - Cada neurônio recebe todas as entradas (atributos), realiza uma soma ponderada delas e aplica uma função não-linear sobre o resultado dessa soma, resultando na ativação interna do neurônio.\n",
    "            - **ELM: Os pesos sinápticos que ponderam as entradas são inicializados aleatoriamente e mantidos constantes, isto é, os pesos não são ajustados durante o processo de treinamento.**\n",
    "            - O número de neurônios, a forma de inicialização e o tipo de função de ativação utilizada são pré-definidas.\n",
    "            - Exemplos de funções de ativação: função logística, tangente hiperbólica, ReLU, Leaky-ReLU.\n",
    "        - Camada de saída:\n",
    "            - A função é combinam a informação produzida pela camada intermediária.\n",
    "            - O número de neurônios da camada de saída deve ser compatível com a estrutura das saídas conhecidas.\n",
    "            - **ELM: Os pesos sinápticos dos neurônios da camada de saída são os parâmetros ajustáveis a serem determinados.**\n",
    "            - **ELM: A função de ativação dos neurônios é a função identidade. Logo, a camada de saída apenas combina linearmente os mapeamentos gerados pela camada intermediária.**\n",
    "    - Observações:\n",
    "        - Como a camada intermediária não participa do processo de treinamento, podemos dizer que sua função é simplesmente aplicar uma transformação não-linear nos dados de entrada, gerando \"novos\" dados de entrada para a camada de saída.\n",
    "        - Como apenas os pesos dos neurônios da camada de saída são ajustáveis e as funções de ativação dos neurônios são funções identidade, o problema de treinamento é linear nos parâmetros ajustáveis.\n",
    "        - Logo, o método de solução do para uma Máquina de Aprendizado Extremo é o mesmo utilizado na solução do modelo linear visto na Questão 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modelo_elm_mat\"></a>\n",
    "\n",
    "- **Máquina de Aprendizado Extremo (ELM) - Formulação matemática**\n",
    "    - Considere o conjunto de amostras $ \\{\\textbf{x}(i), \\textbf{y}(i)\\}_{i=0}^{N-1}$ em que $\\textbf{x} \\in \\mathbf{R}^K$ e $\\textbf{y} \\in \\mathbf{R}^L$.\n",
    "    - A Máquina de Aprendizado Extremo apresenta *M* neurônios na camada intermediária e *L* neurônios na camada de saída.\n",
    "    - Como cada um dos neurônios da camada intermediária recebe todas as entradas de uma amostra, cada um desses neurônios é constituído por *K* pesos sinápticos **gerados aleatoriamente**.\n",
    "    - Matricialmente, podemos agrupar os pesos da seguinte forma:\n",
    "$$\\textbf{V}=\\begin{bmatrix} v_0^{(0)} & v_0^{(1)} & \\ldots & v_0^{(M-1)} \\\\ v_1^{(0)} & v_1^{(1)} & \\ldots & v_1^{(M-1)} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ v_K^{(0)} & v_K^{(1)} & ... & v_K^{(M-1)} \\end{bmatrix}$$\n",
    "&nbsp;\n",
    "        - Cada coluna da matriz $V$ contém os pesos de um neurônio.\n",
    "        - Logo, a dimensão da matriz $V$ é *K x M*.\n",
    "    - Empilhando todas as amostras de entrada na matriz $X$ de dimensão *N x K* e multiplicando as matrizes $X$ e $V$, obtemos a matriz de ativação interna $U_{NxM}$:\n",
    "$$ U = \\begin{bmatrix} u_{00} & u_{01} & \\ldots & u_{0(M-1)} \\\\ u_{10} & u_{11} & \\ldots & u_{1(M-1)} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ u_{(N-1)0} & u_{(N-1)1} & ... & u_{(N-1)(M-1)} \\end{bmatrix}$$\n",
    "&nbsp;\n",
    "        - Cada linha da matriz $U$ contém as ativações internas dos neurônios da camada intermediária para cada uma das amostras de entrada.\n",
    "    - Basta, portanto, aplicar a função de ativação não-linear $f(u)$ em cada um dos elementos da matriz $U$, resultando na matriz de saída $S$ da camada intermediária:\n",
    "$$ S = \\begin{bmatrix} f(u_{00}) & f(u_{01}) & \\ldots & f(u_{0(M-1)}) \\\\ f(u_{10}) & f(u_{11}) & \\ldots & f(u_{1(M-1)}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ f(u_{(N-1)0}) & f(u_{(N-1)1}) & ... & f(u_{(N-1)(M-1)}) \\end{bmatrix}$$\n",
    "&nbsp;\n",
    "    - A partir deste ponto, a construção do problema de otimização é a mesma que a realizada para o modelo de classificação linear, com as seguintes observações:\n",
    "        - A matriz $\\Phi$ é construída a partir da matriz de saída $S$ da camada intermediária.\n",
    "$$ \\Phi = \\begin{bmatrix} 1 & f(u_{00}) & \\ldots & f(u_{0(M-1)}) \\\\ 1 & f(u_{10}) & \\ldots & f(u_{1(M-1)}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & f(u_{(N-1)0}) & ... & f(u_{(N-1)(M-1)}) \\end{bmatrix}$$\n",
    "&nbsp;\n",
    "        - A matriz $W$ de parâmetros ajustáveis contém os pesos sinápticos dos *L* neurônios da camada de saída da ELM.\n",
    "$$ W = \\begin{bmatrix} w_0^{(0)} & w_0^{(1)} & \\ldots & w_0^{(L-1)} \\\\ w_1^{(0)} & w_1^{(1)} & \\ldots & w_1^{(L-1)} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_M^{(0)} & w_M^{(1)} & ... & w_M^{(L-1)} \\end{bmatrix}$$\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"consideracoes\"></a>\n",
    "- **Considerações para utilizar o modelo de regressão como classificador:**\n",
    "    - Cada coluna das matrizes $Y$ e $\\hat{Y}$ corresponde a uma classe.\n",
    "    - Cada coluna de $W$ corresponde a um classificador, de modo que cada um deles é responsável por produzir uma saída referente a uma das classes do problema.\n",
    "    - Novamente, as saídas desejadas de cada amostra (linhas de $Y$) estão na representação *one-hot encoding*.\n",
    "    - As saídas estimadas de cada amostra (linhas de $\\hat{Y}$) são números reais.\n",
    "    - Para definir a classe estimada pelo classificador linear a partir dos números reais gerados na saída, consideraremos que a classe estimada é aquela associada ao maior valor produzido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier():\n",
    "    \n",
    "    def __init__(self, Xtrain, Ytrain, Xpred, Ypred):\n",
    "        self.Xt = Xtrain\n",
    "        self.Yt = Ytrain\n",
    "        self.Xp = Xpred\n",
    "        self.Yp = Ypred\n",
    "        [self.Nt, self.K] = Xtrain.shape\n",
    "        self.Np = Xpred.shape[0]\n",
    "\n",
    "        # variáveis de treinamento:\n",
    "        self.Im = np.insert(np.insert(np.eye(self.K), 0, np.zeros([1, self.K]), axis=0), 0, np.zeros([1, self.K+1]), axis=1)\n",
    "        self.Phi_t = np.insert(self.Xt, 0, np.ones([1, self.Nt]), axis=1)\n",
    "        self.W = None\n",
    "        \n",
    "        # variáveis de predição\n",
    "        self.Phi_p = np.insert(self.Xp, 0, np.ones([1, self.Np]), axis=1)\n",
    "        self.Yest = None  # saídas estimadas na predição\n",
    "        self.Yest_onehot = None # saídas estimadas na predição dadas na representação one-hot encoding\n",
    "    \n",
    "    def fit(self, coefReg):\n",
    "        self.W = np.linalg.inv(np.transpose(self.Phi_t).dot(self.Phi_t) + coefReg*self.Im).dot(np.transpose(self.Phi_t).dot(self.Yt))\n",
    "    \n",
    "    def predict(self):\n",
    "        self.Yest = self.Phi_p.dot(self.W)\n",
    "        LinearClassifier.onehotencoding(self)\n",
    "        \n",
    "    def onehotencoding(self):\n",
    "        # Cria uma matriz de saídas estimadas na representação one-hot encoding:\n",
    "        self.Yest_onehot = self.Yest.copy()\n",
    "        for i in range(0, self.Yest_onehot.shape[0]):   \n",
    "            np.place(self.Yest_onehot[i], self.Yest_onehot[i] < np.max(self.Yest_onehot[i]), 0)\n",
    "            np.place(self.Yest_onehot[i], self.Yest_onehot[i] == np.max(self.Yest_onehot[i]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELM(LinearClassifier):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"param_desempenho\"></a>\n",
    "- **Parâmetros de desempenho**\n",
    "    - Duas métricas são utilizadas para analisar o desempenho do classificador linear: erro quadrático médio e erro de classificação.\n",
    "    - Erro Quadrático Médio (MSE):\n",
    "$$MSE = \\frac{1}{NL}\\sum_{i=0}^{N-1}\\sum_{k=0}^{L-1}[y_k(i)-\\hat{y}_k(i)]^2$$\n",
    "    - Taxa de Erro de Classificação (CE):\n",
    "$$ CE = \\frac{N_{erro}}{N} $$\n",
    "&nbsp;\n",
    "\n",
    "    onde $N_{erro}$ indica o número de amostras classificadas incorretamente.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \n",
    "    def __init__(self, Y, Yest, Yest_onehot):\n",
    "        self.Y = Y\n",
    "        self.Yest = Yest\n",
    "        self.Yest_onehot = Yest_onehot    \n",
    "        self.MSE = None\n",
    "        self.CE = None\n",
    "    \n",
    "    def meansquared_error(self):\n",
    "        e = (self.Y - self.Yest)**2\n",
    "        self.MSE = np.sum(np.sum(e, axis=1), axis=0) # / (N*L), onde [N, L] = self.Yval.shape\n",
    "        return self.MSE\n",
    "    \n",
    "    def classification_error(self):\n",
    "        matches = []\n",
    "        \n",
    "        for i in range(0, self.Y.shape[0]):\n",
    "            matches.append(np.array_equal(self.Y[i], self.Yest_onehot[i]))\n",
    "        \n",
    "        score = matches.count(True)\n",
    "        err = self.Y.shape[0] - score\n",
    "        self.CE = err/(err + score)\n",
    "        return self.CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "<a id=\"resolucao\"></a>\n",
    "### Questão 1 - Resolução do problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inicialmente será feito uma busca pelos coeficientes de regularização $\\lambda$, entre os valores abaixo, que levem aos menores valores de erro quadrático médio e taxa de erro de classificação. \n",
    "$$ A = \\{2^{-10},\\; 2^{-8}, \\ldots,\\; 2^{0},\\; 2^{+2},\\ldots,\\; 2^{+20} \\}$$\n",
    "&nbsp;\n",
    "    - Para cada $\\lambda$ do conjunto $A$:\n",
    "        - Treinar o modelo (obter a matriz $W$) com os dados de treinamento.\n",
    "        - Estimar as saídas $\\hat{Y}$ para os dados de validação.\n",
    "        - Calcular e armazenar o erro quadrático médio e o erro de classificação para os dados de validação.\n",
    "    - Os resultados são reportados por meio de gráficos semilog do desempenho dos classificadores junto aos dados de validação.\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "- Em seguida, será feita uma busca refinada entorno dos dois coeficientes de regularização obtidos anteriormente.\n",
    "    - Implementar o mesmo algoritmo acima.\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "- Para o coeficiente de regularização que levou ao melhor desempenho associado ao erro de classificação:\n",
    "    - Treinar o modelo com todos os dados de treinamento (conjunto de 60.000 amostras)\n",
    "    - Estimar as saídas $\\hat{Y}$ para os dados de teste.\n",
    "    - Resultados:\n",
    "        - Obter a matriz de parâmetros $W$.\n",
    "        - Um gráfico de calor para os parâmetros de cada um dos 10 classificadores lineares.\n",
    "        - Matriz de confusão do classificador quando aplicado ao conjunto de teste.\n",
    "        - Exemplos de dados classificados incorretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_elm\"> </a>\n",
    "- **Especificações e construção da ELM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"busca_inicial\"> </a>\n",
    "- **Etapa de treinamento e validação - Busca inicial pelos melhores coeficientes de regularização:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia da classe LinearClassifier utilizado nas etapas de treinamento e validação:\n",
    "classifier = LinearClassifier(Xtrain, Ytrain, Xval, Yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A1\"> </a>\n",
    "- Treinamento e validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = [2**n for n in range(-10, 21, 2)]\n",
    "\n",
    "ms_errors = np.array([]) # Armazena os valores de erros quadráticos médios\n",
    "ce_errors = np.array([]) # Armazena os valores de erros de classificação\n",
    "best_coefs_MSE = []\n",
    "best_coefs_CE = []\n",
    "\n",
    "for coef in coefs:\n",
    "    classifier.fit(coef) # treinamento\n",
    "    classifier.predict() # validação\n",
    "    \n",
    "    desempenho = Metrics(Yval, classifier.Yest, classifier.Yest_onehot)\n",
    "    \n",
    "    ms_errors = np.append(ms_errors, desempenho.meansquared_error())\n",
    "    ce_errors = np.append(ce_errors, desempenho.classification_error())\n",
    "\n",
    "best_coefs_MSE.append(coefs[np.argmin(ms_errors)])  # melhor coef. de regularização considerando o erro quadrático médio\n",
    "best_coefs_CE.append(coefs[np.argmin(ce_errors)])  # melhor coef. de regularização considerando o erro de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A2\"> </a>\n",
    "- Melhores coeficientes de regularização obtidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_errors1 = ms_errors.copy()\n",
    "ce_errors1 = ce_errors.copy()\n",
    "print(f'Coeficiente de regularização para o menor erro quadrático médio: {best_coefs_MSE}')\n",
    "print(f'Coeficiente de regularização para o menor erro de classificação: {best_coefs_CE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A3\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação considerando o erro quadrático médio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefs = [2**n for n in range(-10, 21, 2)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs[0:13], ms_errors1[0:13], color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xticks()\n",
    "plt.title('Desempenho dos classificadores considerando o erro quadrático médio \\n nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Erro Quadrático Médio')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('desempenho_mse_busca_inicial.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A4\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de classificação correta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs[0:13], [1-erro for erro in ce_errors1[0:13]], color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.title('Desempenho dos classificadores considerando a taxa de classificação \\ncorreta nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Taxa de classificação correta')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('desempenho_taxaacerto_busca_inicial.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A5\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de erro de classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefs = [2**n for n in range(-10, 21, 2)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs[0:13], ce_errors1[0:13], color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.title('Desempenho dos classificadores considerando a taxa de erro de \\nclassificação nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Taxa de erro de classificação')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('desempenho_taxaerro_busca_inicial.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"busca_refinada_MSE\"> </a>\n",
    "- **Etapa de treinamento e validação - Busca refinada pelo melhor coeficiente de regularização considerando o erro quadrático médio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"B1\"> </a>\n",
    "- Treinamento e validação do modelo para 200 valores de $\\lambda$ no intervalo $[10, 100]$ linearmente espaçados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.linspace(10, 111, num=200)\n",
    "\n",
    "ms_errors = np.array([]) # Armazena os valores de erros quadráticos médios\n",
    "\n",
    "for coef in coefs:\n",
    "    classifier.fit(coef) # treinamento\n",
    "    classifier.predict() # validação\n",
    "    \n",
    "    desempenho = Metrics(Yval, classifier.Yest, classifier.Yest_onehot)\n",
    "    ms_errors = np.append(ms_errors, desempenho.meansquared_error())\n",
    "    \n",
    "best_coefs_MSE.append(coefs[np.argmin(ms_errors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"B2\"> </a>\n",
    "- Melhor coeficiente de regularização obtido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_errors2 = ms_errors.copy()\n",
    "\n",
    "print(f'Coeficiente de regularização para o menor erro quadrático médio: {best_coefs_MSE}')\n",
    "print(f'Coeficiente de regularização para o menor erro de classificação: {best_coefs_CE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"B3\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação considerando o erro quadrático médio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs, ms_errors2, color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.title('Desempenho dos classificadores considerando o erro quadrático médio \\n nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Erro quadrático médio')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('desempenho_mse_busca_refinada.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"busca_refinada_CE\"> </a>\n",
    "- **Etapa de treinamento e validação - Busca refinada pelo melhor coeficiente de regularização considerando o erro de classificação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"C1\"> </a>\n",
    "- Treinamento e validação do modelo para 200 valores de $\\lambda$ no intervalo $[10^2,10^4]$ espaçados logaritmicamente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.logspace(2, 4, num=200)\n",
    "\n",
    "ce_errors = [] # Armazena os valores de erros de classificação\n",
    "\n",
    "for coef in coefs:\n",
    "    classifier.fit(coef) # treinamento\n",
    "    classifier.predict() # validação\n",
    "    \n",
    "    desempenho = Metrics(Yval, classifier.Yest, classifier.Yest_onehot)\n",
    "    ce_errors.append(desempenho.classification_error())\n",
    "\n",
    "best_coefs_CE.append(coefs[np.argmin(ce_errors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"C2\"> </a>\n",
    "- Melhor coeficiente de regularização obtido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_errors2 = ce_errors.copy()\n",
    "\n",
    "print(f'Coeficiente de regularização para o menor erro quadrático médio: {best_coefs_MSE}')\n",
    "print(f'Coeficiente de regularização para o menor erro de classificação: {best_coefs_CE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"C3\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de classificação correta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefs = np.logspace(2, 4, num=100)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs, [1-erro for erro in ce_errors2], color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.title('Desempenho dos classificadores considerando a taxa de classificação \\ncorreta nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Taxa de classificação correta')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('desempenho_taxaacerto_busca_refinada.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"C4\"> </a>\n",
    "- Gráfico semilog do desempenho dos classificadores junto aos dados de validação consideranda taxa de erro de classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.logspace(2, 4, num=200)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.semilogx(coefs, ce_errors2, color='b')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.title('Desempenho dos classificadores considerando a taxa de erro de \\nclassificação nos dados de validação', fontsize=13)\n",
    "plt.xlabel('Coeficiente de Regularização')\n",
    "plt.ylabel('Taxa de erro de classificação')\n",
    "plt.show()\n",
    "#plt.savefig('desempenho_taxaerro_busca_refinada.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_coefs = np.array([best_coefs_MSE, best_coefs_CE])\n",
    "print(best_coefs)\n",
    "print(best_coefs.shape)\n",
    "\n",
    "# np.savetxt('melhores_coeficientes.txt', best_coefs, fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"teste\"> </a>\n",
    "- **Etapa de teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia da classe LinearClassifier utilizado nas etapas de obtenção do modelo final e teste:\n",
    "best_classifier = LinearClassifier(X, Y, Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"D1\"> </a>\n",
    "- Treinamento do modelo com os 60.000 dados de treinamento e predição com os 10.000 dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = best_coefs_CE[-1]\n",
    "\n",
    "best_classifier.fit(coef) #treinamento\n",
    "best_classifier.predict()\n",
    "\n",
    "desempenho = Metrics(Ytest, best_classifier.Yest, best_classifier.Yest_onehot)\n",
    "\n",
    "ms_error = desempenho.meansquared_error()\n",
    "ce_error = desempenho.classification_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = np.array([coef, ms_error, ce_error])\n",
    "\n",
    "# np.savetxt('metricas_classificador_final.txt', metricas, fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"D2\"> </a>\n",
    "- Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_categorical = np.array(tuple(map(onehot_to_categorical, Ytest)))\n",
    "Yest_categorical = np.array(tuple(map(onehot_to_categorical, best_classifier.Yest_onehot)))\n",
    "\n",
    "index = [i for i in \"1234567890\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Matriz de Confusão', fontsize=20)\n",
    "plt.xlabel('Classes Verdadeiras')\n",
    "plt.ylabel('Classes Estimadas')\n",
    "sns.heatmap(confusion_matrix(Ytest_categorical, Yest_categorical), annot=True, annot_kws={'size': 10}, square=True, fmt='d', xticklabels=index, yticklabels=index, cmap='Blues_r');\n",
    "\n",
    "#plt.savefig('matriz_de_confusao.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"D3\"> </a>\n",
    "- Matriz de parâmetros do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = best_classifier.W\n",
    "print(W.shape)\n",
    "\n",
    "#np.savetxt('matriz_parametros_W.txt', W, fmt='%.10f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"D4\"> </a>\n",
    "- Gráficos de calor para os parâmetros de cada um dos 10 classificadores lineares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wk = np.transpose(np.delete(W, 0, axis=0))\n",
    "Yk = list(range(1, 10))\n",
    "Yk.append(0)\n",
    "\n",
    "print(Wk.shape)\n",
    "print(Yk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "for index, (w_vec, label) in enumerate(zip(Wk[0:10], Yk[0:10])):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    W_image = np.transpose(np.reshape(w_vec, (28, 28)))\n",
    "    sns.heatmap(W_image)\n",
    "    plt.title('Classe: ' + f'{label}\\n', fontsize = 12)\n",
    "\n",
    "#plt.savefig('mapas_de_calor.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"D5\"> </a>\n",
    "- Exemplos de dígitos classificados incorretamente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estErr = np.array([1 if imagem != 0 else 0 for imagem in Ytest_categorical-Yest_categorical])\n",
    "indices = list(np.where(estErr == 1)[0])\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "N = 50\n",
    "\n",
    "for index_subplot, index_amostra in enumerate(indices[N:N+10]):\n",
    "    # print(index_subplot, index_amostra)\n",
    "    plt.subplot(2, 5, index_subplot+1)\n",
    "    X_image = np.transpose(np.reshape(Xtest[index_amostra], (28, 28)))\n",
    "    plt.imshow(X_image, cmap='gray')\n",
    "    plt.title(f'Classe verdadeira: {Ytest_categorical[index_amostra]}\\n Classe estimada: {Yest_categorical[index_amostra]}\\n')\n",
    "    \n",
    "#plt.savefig('digitos_classificados_incorretamente.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
