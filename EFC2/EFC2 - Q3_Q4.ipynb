{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EFC2 - Q3_Q4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOFj36CH11GUr8bvEN3gV+z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XHaK3VtuDEZ0","colab_type":"text"},"source":["# **IA353 - Redes Neurais: EFC2 - Questão 3 e Questão 4**\n","## **Síntese de Modelos Baseados em Redes MLP e Convolucional para Classificação de Padrões**\n","\n","**Professor:** Fernando J. Von Zuben.\n","\n","**Aluno(a)**: Guilherme Rosa"]},{"cell_type":"markdown","metadata":{"id":"0rbv2erBrAep","colab_type":"text"},"source":["### **1. Importações**"]},{"cell_type":"code","metadata":{"id":"1fCvD3lmrH18","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176499863,"user_tz":180,"elapsed":3301,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7kvsbYIrLkF","colab_type":"text"},"source":["### **2. Download da base de dados MNIST**"]},{"cell_type":"markdown","metadata":{"id":"bOQlz-fTr2Vl","colab_type":"text"},"source":["  - A base de dados MNIST é constituída pelos conjuntos de treinamento e teste. O primeiro conjunto possui 60.000 amostras de imagens de dígitos manuscritos, enquanto que o segundo conjunto possui 10.000 amostras.\n","  - As amostras da base MNIST, quando baixadas utilizando a API do Keras, apresentam as seguintes características:\n","    - As entradas estão no formato (28, 28, 1), isto é, uma matriz quadrada com cada pixel no intervalo [0, 255].\n","    - As saídas (rótulos) estão na representação categórica.\n","  - Após o download, os pixels das amostras de entrada passam por um processo de normalização, sendo divididos por 255, de modo que seus valores fiquem no intervalo [0, 1].\n","  - Nesta atividade, a normalização é necessária para que o mapeamento a ser aproximado pelos modelos neurais seja mais suave, facilitando o processo de treinamento (i. e., a obtenção dos parâmetros do modelo).\n","  - As informações referentes ao formato (shape) dos dados de entrada é apresentado nas seções de implementação das redes neurais MLP e convolucional.\n","  - Diferente do que foi feito nas Questões 1 e 2 do EFC1, as saídas não são convertidas para a representação one-hot, pois a função custo **sparse_categorial_crossentropy** converte implicitamente as saídas categóricas para one-hot durante o treinamento."]},{"cell_type":"code","metadata":{"id":"lLrJp-yyrxau","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1600176500337,"user_tz":180,"elapsed":3690,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"11bac542-56dd-459d-b890-652ff4b55c1a"},"source":["(X_train, y), (X_test, y_test) = keras.datasets.mnist.load_data()\n","\n","print('Valores máximo e mínimo antes da normalização:')\n","print(f'  X_train.max: {X_train.max()}')\n","print(f'  X_train.min: {X_train.min()}')\n","\n","X_train, X_test = X_train/255., X_test/255.\n","print('Valores máximo e mínimo após a normalização:')\n","print(f'  X_train.max: {X_train.max()}')\n","print(f'  X_train.min: {X_train.min()}')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","Valores máximo e mínimo antes da normalização:\n","  X_train.max: 255\n","  X_train.min: 0\n","Valores máximo e mínimo após a normalização:\n","  X_train.max: 1.0\n","  X_train.min: 0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kvaHrtY0w0Jx","colab_type":"text"},"source":["### **3. Questão 3: Classificador com Rede Neural MLP**"]},{"cell_type":"markdown","metadata":{"id":"qsUKSO5hy9w9","colab_type":"text"},"source":["#### **3.1. Observações:**"]},{"cell_type":"markdown","metadata":{"id":"i7qRq_cjxeXN","colab_type":"text"},"source":["- As entradas X_train e X_test devem ser convertidas de matriz (28, 28, 1) para vetor (784,) pois as redes neurais com arquitetura fully-connected apenas processam vetores.\n","  \n","- O objetivo do exercício é superar o desempenho da rede MLP proposta no enunciado, cujas especificações e desempenho estão apresentadas na Sub-seção 3.2.\n","\n","- O desempenho utilizado para comparação será um desempenho médio tomado a partir de 5 realizações de uma dada configuração de hiperparâmetros. **A métrica de decisão será a acurácia junto aos dados de validação**.\n","\n","- Os modelos utilizam o Dropout como técnica de regularização. Essa técnica desativa aleatoriamente uma parcela dos neurônios durante o treinamento. Após o treinamento, os pesos de cada neurônio é multiplicada pela probabilidade dele pertencer ao modelo. Assim, para que o modelo resultante seja obtido, **é NECESSÁRIO utilizar a método evaluate**.\n","\n","- Os dados de treinamento são divididos em amostras de treinamento (80%) e amostras de validação (20%)."]},{"cell_type":"markdown","metadata":{"id":"177OeYNX94Ry","colab_type":"text"},"source":["- Mudança do formato dos dados de entrada e separação dos dados em amostras de treinamento e de validação:"]},{"cell_type":"code","metadata":{"id":"6jzhSgq391Yc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176500338,"user_tz":180,"elapsed":3687,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}}},"source":["X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n","\n","N = int(0.8*X_train.shape[0])\n","\n","X_valid, y_valid = X_train[N:], y[N:]\n","X_train, y_train = X_train[:N], y[:N]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CU2XONuHPVi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600176500339,"user_tz":180,"elapsed":3674,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"b85f1030-abc9-42a1-c72c-6899e8a545d3"},"source":["print('Dados de treinamento:')\n","print(f'  Dimensão de X_train: {X_train.shape}')\n","print(f'  Dimensão de y_train: {y_train.shape}')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Dados de treinamento:\n","  Dimensão de X_train: (48000, 784)\n","  Dimensão de y_train: (48000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xfodZZSJHSXL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600176500340,"user_tz":180,"elapsed":3661,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"399933e2-9fbe-46fe-95fa-eb546b8ab80a"},"source":["print('Dados de validação:')\n","print(f'  Dimensão de X_valid: {X_valid.shape}')\n","print(f'  Dimensão de y_valid: {y_valid.shape}')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Dados de validação:\n","  Dimensão de X_valid: (12000, 784)\n","  Dimensão de y_valid: (12000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e-1_Sfc6HTmp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600176500341,"user_tz":180,"elapsed":3646,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"102660af-f426-4034-d3f0-293e6a62ab3e"},"source":["print('Dados de teste:')\n","print(f'  Dimensão de X_test: {X_test.shape}')\n","print(f'  Dimensão de y_test: {y_test.shape}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Dados de teste:\n","  Dimensão de X_test: (10000, 784)\n","  Dimensão de y_test: (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ip54zrmE1DGv","colab_type":"text"},"source":["#### **3.2. Arquitetura proposta no enunciado:**"]},{"cell_type":"markdown","metadata":{"id":"-ud50I9Z1Gkk","colab_type":"text"},"source":["  - Uma camada intermediária com 512 neurônios com funções de ativação ReLU e taxa de ocorrência de *dropout* de 50%.\n","  - Uma camada de saída com 10 neurônios com função de ativação softmax (não deve ser alterada).\n","  - Algoritmo de otimização Adam, aplicado durante 5 épocas e com 32 amostras por mini-batch.\n","  - Função custo (loss): sparse_categorical_crossentropy (não deve ser alterada)."]},{"cell_type":"code","metadata":{"id":"76LPI2xS5hgB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600176590759,"user_tz":180,"elapsed":94048,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"fc0e541d-72ad-47fe-f393-b9556deb3e7c"},"source":["N = 5 # número de realizações\n","\n","metrics = []\n","print(f'Treinamento do modelo proposto:', end=' ')\n","\n","for i in range(1, N+1):\n","\n","    mlp_enunciado = keras.models.Sequential([\n","        keras.layers.Input(shape=(784, )),\n","        keras.layers.Dense(512, activation='relu'),\n","        keras.layers.Dropout(0.5),\n","        keras.layers.Dense(10, activation='softmax')\n","    ])\n","\n","    mlp_enunciado.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    mlp_enunciado.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","    loss_t, acc_t = mlp_enunciado.evaluate(X_train, y_train, verbose=False)\n","    loss_v, acc_v = mlp_enunciado.evaluate(X_valid, y_valid, verbose=False)\n","    metrics.append((loss_t, acc_t, loss_v, acc_v))\n","\n","print(f'Finalizado')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Treinamento do modelo proposto: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_tLTRvM8D1Yw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":77},"executionInfo":{"status":"ok","timestamp":1600176590767,"user_tz":180,"elapsed":94042,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"2cd4db54-c742-426b-c9ef-63c497543926"},"source":["metrics = np.array(metrics)\n","metrics_mean = np.reshape(np.mean(metrics, axis=0), (1, 4))\n","\n","df = pd.DataFrame(metrics_mean, columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=['Modelo proposto'])\n","df"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Modelo proposto</th>\n","      <td>0.036767</td>\n","      <td>0.988808</td>\n","      <td>0.079167</td>\n","      <td>0.977183</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Train_loss  Train_acc  Val_loss   Val_acc\n","Modelo proposto    0.036767   0.988808  0.079167  0.977183"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"fdHl2UrsH5JS","colab_type":"text"},"source":["#### **3.3. Análise do impacto de alguns hiperparâmetros da primeira camada intermediária no desempenho da rede MLP:**"]},{"cell_type":"markdown","metadata":{"id":"5QpqN1jyOlHE","colab_type":"text"},"source":["#####**3.3.1. Impacto de diferentes funções de ativação:**"]},{"cell_type":"code","metadata":{"id":"GCTOxlzOPLQF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1600176925922,"user_tz":180,"elapsed":429182,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"d6abda20-dcc1-4ec0-9f9b-536d581c6304"},"source":["activations = ['sigmoid', 'tanh', 'relu', 'leakyrelu']\n","\n","activation_metrics = {}\n","\n","for ACTIVATION in activations:\n","    print(f'Treinamento do modelo com funções de ativação do tipo {ACTIVATION}:', end=' ')\n","    \n","    metrics = []    \n","    for i in range(1, N+1):\n","\n","        if ACTIVATION != 'leakyrelu':\n","            mlp = keras.models.Sequential([\n","                keras.layers.Input(shape=(784, )),\n","                keras.layers.Dense(512, activation=ACTIVATION),\n","                keras.layers.Dropout(0.5),\n","                keras.layers.Dense(10, activation='softmax')\n","            ])\n","        else:\n","           mlp = keras.models.Sequential([\n","                keras.layers.Input(shape=(784, )),\n","                keras.layers.Dense(512),\n","                keras.layers.LeakyReLU(),\n","                keras.layers.Dropout(0.5),\n","                keras.layers.Dense(10, activation='softmax')\n","            ])\n","    \n","        mlp.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","        mlp.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","        loss_t, acc_t = mlp.evaluate(X_train, y_train, verbose=False)\n","        loss_v, acc_v = mlp.evaluate(X_valid, y_valid, verbose=False)\n","        metrics.append((loss_t, acc_t, loss_v, acc_v))\n","\n","    print('Finalizado')\n","    metrics = np.array(metrics)\n","    metrics_mean = np.mean(metrics, axis=0)\n","    activation_metrics[ACTIVATION] = metrics_mean"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Treinamento do modelo com funções de ativação do tipo sigmoid: Finalizado\n","Treinamento do modelo com funções de ativação do tipo tanh: Finalizado\n","Treinamento do modelo com funções de ativação do tipo relu: Finalizado\n","Treinamento do modelo com funções de ativação do tipo leakyrelu: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cQ_GKyHCSWyY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1600176925931,"user_tz":180,"elapsed":429175,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"17d0cdd9-3512-4f77-caa4-45f244ac963f"},"source":["df = pd.DataFrame(activation_metrics.values(), columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=activation_metrics.keys())\n","df"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sigmoid</th>\n","      <td>0.077281</td>\n","      <td>0.977642</td>\n","      <td>0.104218</td>\n","      <td>0.968917</td>\n","    </tr>\n","    <tr>\n","      <th>tanh</th>\n","      <td>0.076533</td>\n","      <td>0.976508</td>\n","      <td>0.114284</td>\n","      <td>0.966800</td>\n","    </tr>\n","    <tr>\n","      <th>relu</th>\n","      <td>0.038913</td>\n","      <td>0.988083</td>\n","      <td>0.083123</td>\n","      <td>0.975650</td>\n","    </tr>\n","    <tr>\n","      <th>leakyrelu</th>\n","      <td>0.102350</td>\n","      <td>0.969229</td>\n","      <td>0.139170</td>\n","      <td>0.962217</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Train_loss  Train_acc  Val_loss   Val_acc\n","sigmoid      0.077281   0.977642  0.104218  0.968917\n","tanh         0.076533   0.976508  0.114284  0.966800\n","relu         0.038913   0.988083  0.083123  0.975650\n","leakyrelu    0.102350   0.969229  0.139170  0.962217"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"y25Mcz84cGHc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600176925932,"user_tz":180,"elapsed":429161,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"241ac5ee-27f1-4653-9d45-a709e545b841"},"source":["val_accs = [metric[-1] for metric in list(activation_metrics.values())]            # Lista que contém apenas as acurácias de validação\n","activations_val_accs = list(zip(val_accs, list(activation_metrics.keys())))        # Lista que contém o par Função de ativação - Acurácia de validação\n","\n","activations_val_accs.sort(reverse=True)                                            # Ordena as acurácias do maior para o menor\n","best_activation = activations_val_accs[0][1]\n","print(f'Função de ativação que levou ao melhor desempenho: {best_activation}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Função de ativação que levou ao melhor desempenho: relu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zWRCyTsZgosz","colab_type":"text"},"source":["- Como mostra a tabela acima, o uso de funções de ativação sigmoidais (sigmoide e tangente hiperbólica) levaram a modelos com desempenho inferior ao uso da ReLU.\n","\n","- É interessante destacar que neste problema de classificação de dígitos manuscritos, a LeakyReLU também apresentou desempenho médio inferior ao da ReLU."]},{"cell_type":"markdown","metadata":{"id":"zqzhlnf1OsHG","colab_type":"text"},"source":["##### **3.3.2. Impacto de diferentes algoritmos de otimização:**"]},{"cell_type":"code","metadata":{"id":"ZQ9qVInMT2aT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1600177423283,"user_tz":180,"elapsed":926495,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"754b3397-19e3-450b-9437-88e98539acca"},"source":["optimizers = ['sgd', 'sgd+momentum', 'NAG', 'adagrad', 'adadelta', 'adam']\n","\n","optimizers_metrics = {}\n","\n","for OPTIMIZER in optimizers:\n","    print(f'Treinamento do modelo com algoritmo de otimização {OPTIMIZER}:', end=' ')\n","    \n","    metrics = []    \n","    for i in range(1, N+1):\n","        mlp = keras.models.Sequential([\n","            keras.layers.Input(shape=(784, )),\n","            keras.layers.Dense(512, activation='relu'),\n","            keras.layers.Dropout(0.5),\n","            keras.layers.Dense(10, activation='softmax')\n","        ])\n","\n","        if OPTIMIZER == 'sgd+momentum':\n","            opt = keras.optimizers.SGD(momentum=0.9)\n","            mlp.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","        elif OPTIMIZER == 'NAG':\n","            opt = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n","            mlp.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","        else:\n","            mlp.compile(loss='sparse_categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n","        \n","        mlp.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","        loss_t, acc_t = mlp.evaluate(X_train, y_train, verbose=False)\n","        loss_v, acc_v = mlp.evaluate(X_valid, y_valid, verbose=False)\n","        metrics.append((loss_t, acc_t, loss_v, acc_v))\n","\n","    print('Finalizado')\n","    metrics = np.array(metrics)\n","    metrics_mean = np.mean(metrics, axis=0)\n","    optimizers_metrics[OPTIMIZER] = metrics_mean"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Treinamento do modelo com algoritmo de otimização sgd: Finalizado\n","Treinamento do modelo com algoritmo de otimização sgd+momentum: Finalizado\n","Treinamento do modelo com algoritmo de otimização NAG: Finalizado\n","Treinamento do modelo com algoritmo de otimização adagrad: Finalizado\n","Treinamento do modelo com algoritmo de otimização adadelta: Finalizado\n","Treinamento do modelo com algoritmo de otimização adam: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s5yElREFXWIL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"ok","timestamp":1600177423285,"user_tz":180,"elapsed":926481,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"0db8e894-0c5e-4106-d41a-d846e2bf71c6"},"source":["df = pd.DataFrame(optimizers_metrics.values(), columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=optimizers_metrics.keys())\n","df"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sgd</th>\n","      <td>0.224920</td>\n","      <td>0.937496</td>\n","      <td>0.218798</td>\n","      <td>0.939967</td>\n","    </tr>\n","    <tr>\n","      <th>sgd+momentum</th>\n","      <td>0.059615</td>\n","      <td>0.983237</td>\n","      <td>0.086807</td>\n","      <td>0.974450</td>\n","    </tr>\n","    <tr>\n","      <th>NAG</th>\n","      <td>0.060603</td>\n","      <td>0.982892</td>\n","      <td>0.088125</td>\n","      <td>0.974317</td>\n","    </tr>\n","    <tr>\n","      <th>adagrad</th>\n","      <td>0.402463</td>\n","      <td>0.896254</td>\n","      <td>0.375811</td>\n","      <td>0.904800</td>\n","    </tr>\n","    <tr>\n","      <th>adadelta</th>\n","      <td>1.504049</td>\n","      <td>0.731687</td>\n","      <td>1.484198</td>\n","      <td>0.750217</td>\n","    </tr>\n","    <tr>\n","      <th>adam</th>\n","      <td>0.036506</td>\n","      <td>0.988792</td>\n","      <td>0.078927</td>\n","      <td>0.976600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Train_loss  Train_acc  Val_loss   Val_acc\n","sgd             0.224920   0.937496  0.218798  0.939967\n","sgd+momentum    0.059615   0.983237  0.086807  0.974450\n","NAG             0.060603   0.982892  0.088125  0.974317\n","adagrad         0.402463   0.896254  0.375811  0.904800\n","adadelta        1.504049   0.731687  1.484198  0.750217\n","adam            0.036506   0.988792  0.078927  0.976600"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"J-qScTkIjVGO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600177423287,"user_tz":180,"elapsed":926467,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"c8c01451-d531-4ffc-a94e-42d3949dc03a"},"source":["val_accs = [metric[-1] for metric in list(optimizers_metrics.values())]            # Lista que contém apenas as acurácias de validação\n","optimizers_val_accs = list(zip(val_accs, list(optimizers_metrics.keys())))         # Lista que contém o par Algoritmo de Otimização - Acurácia de validação\n","\n","optimizers_val_accs.sort(reverse=True)                                             # Ordena as acurácias do maior para o menor\n","best_optimizer = optimizers_val_accs[0][1]\n","print(f'Algoritmo de otimização que levou ao melhor desempenho: {best_optimizer}')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Algoritmo de otimização que levou ao melhor desempenho: adam\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hB4DzFFzcocy","colab_type":"text"},"source":["- Conforme mostra a tabela acima, os algoritmos que levaram à redes com os piores desempenhos médios foram o SGD, Adagrad e Adadelta.\n","\n","- No caso do SGD, esse desempenho insatisfatório deve-se ao algoritmo não apresentar um passo adaptativo, isto é, o valor fixo para o passo de ajuste dos parâmetros deve ter sido muito pequeno, a ponto de convergir para um mínimo local ruim.\n","\n","- No caso do Adagrad, apresentou um desempenho ruim mesmo sendo um algoritmo adaptativo. Isso ocorre pois a cada iteração os passos de ajuste dos pesos decrescem monotonicamente, levando-o a convergir para um mínimo ainda pior que o do SGD. \n","\n","- Por fim, observa-se que o Adadelta se mostrou como o pior algoritmo. Em teoria ele deveria levar a um desempenho superior ao do Adagrad, pois sua formulação combate o problema de decrescimento monotônico.\n","\n","- Por outro lado, os algoritmos que levaram à redes com os melhores desempenhos médios foram SGD+momentum, NAG e Adam, sendo este último o melhor."]},{"cell_type":"markdown","metadata":{"id":"dMRMZ7gMO0Rb","colab_type":"text"},"source":["##### **3.3.3. Impacto do número de neurônios:**"]},{"cell_type":"code","metadata":{"id":"KF6cbvZnXsCQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1600177844511,"user_tz":180,"elapsed":1347675,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"66f4acca-1684-4a18-c34c-b686b9d31921"},"source":["units = [100, 300, 512, 700, 900]\n","\n","units_metrics = {}\n","\n","for NUM_UNITS in units:\n","    print(f'Treinamento do modelo com {NUM_UNITS} neurônios na camada intermediária:', end=' ')\n","    \n","    metrics = []    \n","    for i in range(1, N+1):\n","        mlp = keras.models.Sequential([\n","            keras.layers.Input(shape=(784, )),\n","            keras.layers.Dense(NUM_UNITS, activation='relu'),\n","            keras.layers.Dropout(0.5),\n","            keras.layers.Dense(10, activation='softmax')\n","        ])\n","        \n","        mlp.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","        mlp.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","        loss_t, acc_t = mlp.evaluate(X_train, y_train, verbose=False)\n","        loss_v, acc_v = mlp.evaluate(X_valid, y_valid, verbose=False)\n","        metrics.append((loss_t, acc_t, loss_v, acc_v))\n","\n","    print('Finalizado')\n","    metrics = np.array(metrics)\n","    metrics_mean = np.mean(metrics, axis=0)\n","    units_metrics[str(NUM_UNITS)] = metrics_mean"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Treinamento do modelo com 100 neurônios na camada intermediária: Finalizado\n","Treinamento do modelo com 300 neurônios na camada intermediária: Finalizado\n","Treinamento do modelo com 512 neurônios na camada intermediária: Finalizado\n","Treinamento do modelo com 700 neurônios na camada intermediária: Finalizado\n","Treinamento do modelo com 900 neurônios na camada intermediária: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FaTaB7DgYt4i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1600177844513,"user_tz":180,"elapsed":1347661,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"b74c44f2-4515-44a7-c77f-4529ee5951bb"},"source":["df = pd.DataFrame(units_metrics.values(), columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=units_metrics.keys())\n","df"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>100</th>\n","      <td>0.085686</td>\n","      <td>0.974825</td>\n","      <td>0.111537</td>\n","      <td>0.968167</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>0.044490</td>\n","      <td>0.986642</td>\n","      <td>0.083971</td>\n","      <td>0.975133</td>\n","    </tr>\n","    <tr>\n","      <th>512</th>\n","      <td>0.037403</td>\n","      <td>0.988442</td>\n","      <td>0.081164</td>\n","      <td>0.976017</td>\n","    </tr>\n","    <tr>\n","      <th>700</th>\n","      <td>0.037202</td>\n","      <td>0.988133</td>\n","      <td>0.083478</td>\n","      <td>0.975317</td>\n","    </tr>\n","    <tr>\n","      <th>900</th>\n","      <td>0.033207</td>\n","      <td>0.989600</td>\n","      <td>0.080359</td>\n","      <td>0.976617</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Train_loss  Train_acc  Val_loss   Val_acc\n","100    0.085686   0.974825  0.111537  0.968167\n","300    0.044490   0.986642  0.083971  0.975133\n","512    0.037403   0.988442  0.081164  0.976017\n","700    0.037202   0.988133  0.083478  0.975317\n","900    0.033207   0.989600  0.080359  0.976617"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"70NOfabajpfR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600177844515,"user_tz":180,"elapsed":1347648,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"c077afcf-911e-41fb-b094-1a25e9c8dd66"},"source":["val_accs = [metric[-1] for metric in list(units_metrics.values())]      # Lista que contém apenas as acurácias de validação\n","units_val_accs = list(zip(val_accs, list(units_metrics.keys())))        # Lista que contém o par Número de neurônios - Acurácia de validação\n","\n","units_val_accs.sort(reverse=True)                                       # Ordena as acurácias do maior para o menor\n","best_units = units_val_accs[0][1]\n","print(f'Número de neurônios que levou ao melhor desempenho: {best_units}')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Número de neurônios que levou ao melhor desempenho: 900\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v1Dz0Ywffe5Q","colab_type":"text"},"source":["- Conforme mostra a tabela acima, a rede MLP com 900 neurônios na camada intermediária apresentou um desempenho médio levemente superior ao da arquitetura proposta com 512 neurônios.\n","\n","- Isso nos leva a concluir que o aumento da flexibilidade do modelo com a inserção de mais neurônios na camada intermediária não leva a uma melhora significativa do desempenho."]},{"cell_type":"markdown","metadata":{"id":"tK7oyV15O6Hz","colab_type":"text"},"source":["##### **3.3.4. Impacto da taxa de ocorrência de dropout:**"]},{"cell_type":"markdown","metadata":{"id":"R1jIc-W6JhIn","colab_type":"text"},"source":["- Como as técnicas de regularização dependem da flexibilidade do modelo, não faria sentido analisar o impacto da taxa de ocorrência de Dropout considerando os 512 neurônios na camada intermediária da arquitetura proposta e, em seguida, criar um modelo que combine todos os melhores hiperparâmetros obtidos *best_activation*, *best_optimizer*, *best_units* e *best_rate*.\n","\n","- Diante disso, a análise do impacto da taxa de ocorrência de Dropout é feita considerando os melhores valores para os 3 hiperparâmetros já analisados *best_activation*, *best_optimizer*, *best_units*."]},{"cell_type":"code","metadata":{"id":"d31RHD5usNs5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1600180071016,"user_tz":180,"elapsed":430904,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"96d79b8c-4522-41e9-e480-84009a1a30ac"},"source":["dropout_rates = [0.1, 0.3, 0.5, 0.7, 0.9]\n","\n","rates_metrics = {}\n","\n","for DROPOUT_RATE in dropout_rates:\n","    print(f'Treinamento do modelo com taxa de dropout de {DROPOUT_RATE*100}%:', end=' ')\n","    \n","    metrics = []    \n","    for i in range(1, N+1):\n","        mlp = keras.models.Sequential([\n","            keras.layers.Input(shape=(784, )),\n","            keras.layers.Dense(best_units, activation=best_activation),\n","            keras.layers.Dropout(DROPOUT_RATE),\n","            keras.layers.Dense(10, activation='softmax')\n","        ])\n","        \n","        mlp.compile(loss='sparse_categorical_crossentropy', optimizer=best_optimizer, metrics=['accuracy'])\n","        mlp.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","        loss_t, acc_t = mlp.evaluate(X_train, y_train, verbose=False)\n","        loss_v, acc_v = mlp.evaluate(X_valid, y_valid, verbose=False)\n","        metrics.append((loss_t, acc_t, loss_v, acc_v))\n","\n","    print('Finalizado')\n","    metrics = np.array(metrics)\n","    metrics_mean = np.mean(metrics, axis=0)\n","    rates_metrics[DROPOUT_RATE] = metrics_mean"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Treinamento do modelo com taxa de dropout de 10.0%: Finalizado\n","Treinamento do modelo com taxa de dropout de 30.0%: Finalizado\n","Treinamento do modelo com taxa de dropout de 50.0%: Finalizado\n","Treinamento do modelo com taxa de dropout de 70.0%: Finalizado\n","Treinamento do modelo com taxa de dropout de 90.0%: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nKa2ve1YJTRA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1600180074862,"user_tz":180,"elapsed":1576,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"9224dd1f-c7cb-41cb-a572-4c3a28427b32"},"source":["df = pd.DataFrame(rates_metrics.values(), columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=rates_metrics.keys())\n","df"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.1</th>\n","      <td>0.023935</td>\n","      <td>0.992175</td>\n","      <td>0.090907</td>\n","      <td>0.975483</td>\n","    </tr>\n","    <tr>\n","      <th>0.3</th>\n","      <td>0.025981</td>\n","      <td>0.991717</td>\n","      <td>0.084010</td>\n","      <td>0.976817</td>\n","    </tr>\n","    <tr>\n","      <th>0.5</th>\n","      <td>0.031324</td>\n","      <td>0.990192</td>\n","      <td>0.079429</td>\n","      <td>0.978233</td>\n","    </tr>\n","    <tr>\n","      <th>0.7</th>\n","      <td>0.051205</td>\n","      <td>0.984033</td>\n","      <td>0.088202</td>\n","      <td>0.974667</td>\n","    </tr>\n","    <tr>\n","      <th>0.9</th>\n","      <td>0.118692</td>\n","      <td>0.965154</td>\n","      <td>0.130039</td>\n","      <td>0.963000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Train_loss  Train_acc  Val_loss   Val_acc\n","0.1    0.023935   0.992175  0.090907  0.975483\n","0.3    0.025981   0.991717  0.084010  0.976817\n","0.5    0.031324   0.990192  0.079429  0.978233\n","0.7    0.051205   0.984033  0.088202  0.974667\n","0.9    0.118692   0.965154  0.130039  0.963000"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"mvm0q1dFKVW6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600180076930,"user_tz":180,"elapsed":3634,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"c5c56162-140a-422b-eda2-25c11c964355"},"source":["val_accs = [metric[-1] for metric in list(rates_metrics.values())]      # Lista que contém apenas as acurácias de validação\n","rates_val_accs = list(zip(val_accs, list(rates_metrics.keys())))        # Lista que contém o par Taxa de Dropout - Acurácia de validação\n","\n","rates_val_accs.sort(reverse=True)                                       # Ordena as acurácias do maior para o menor\n","best_rate = rates_val_accs[0][1]\n","print(f'Taxa de Dropout que levou ao melhor desempenho: {best_rate}')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Taxa de Dropout que levou ao melhor desempenho: 0.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Gyh9ne3aLib","colab_type":"text"},"source":["##### **3.3.5. Discussão**"]},{"cell_type":"markdown","metadata":{"id":"OZShSr3KbQql","colab_type":"text"},"source":["- Vimos na seção 3.3 como o desempenho médio da rede neural MLP com uma única camada intermediária é afetada com a variação da função de ativação, algoritmo de otimização, número de neurônios da camada oculta e taxa de dropout.\n","\n","- Na subseção 3.3.4 foram combinados os melhores valores de hiperparâmetros. Contudo, a arquitetura resultante não levou a um aumento significativo da acurácia junto aos dados de validação.\n","\n","- Com isso, somos motivados a estudar redes MLP com mais camadas intermediárias e investigar se um aumento maior no desempenho médio é alcançado. "]},{"cell_type":"markdown","metadata":{"id":"otrEJ4UVhaC3","colab_type":"text"},"source":["#### **3.4. Análise do impacto da inserção de uma segunda camada intermediária no desempenho da rede MLP:**"]},{"cell_type":"markdown","metadata":{"id":"H5v9fzdoLUwL","colab_type":"text"},"source":["#### **3.5. Arquitetura com desempenho superior:**"]},{"cell_type":"markdown","metadata":{"id":"vsK5kxXOLfE-","colab_type":"text"},"source":["- Na sub-seção 3.3.4 foi obtido uma arquitetura com desempenho médio superior ao da arquitetura proposta no enunciado.\n","\n","- Hiperparâmetros:\n","\n","\n","- A seguir, ambas as arquiteturas são retreinadas e os desempenhos médios são tomados a partir de 10 realizações."]},{"cell_type":"code","metadata":{"id":"4bF0_RR5MKcq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600181317278,"user_tz":180,"elapsed":165191,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"967e8583-d293-4d27-9d8b-6e710a274429"},"source":["N = 10 # número de realizações\n","\n","metrics_mlp_enunciado = []\n","print(f'Treinamento do modelo proposto:', end=' ')\n","\n","for i in range(1, N+1):\n","\n","    mlp_enunciado = keras.models.Sequential([\n","        keras.layers.Input(shape=(784, )),\n","        keras.layers.Dense(512, activation='relu'),\n","        keras.layers.Dropout(0.5),\n","        keras.layers.Dense(10, activation='softmax')\n","    ])\n","\n","    mlp_enunciado.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    mlp_enunciado.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","    loss_t, acc_t = mlp_enunciado.evaluate(X_train, y_train, verbose=False)\n","    loss_v, acc_v = mlp_enunciado.evaluate(X_valid, y_valid, verbose=False)\n","    metrics_mlp_enunciado.append((loss_t, acc_t, loss_v, acc_v))\n","\n","print(f'Finalizado')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Treinamento do modelo proposto: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SVYQf3AmMWJF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600181487438,"user_tz":180,"elapsed":333263,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"0c0ff07a-2cb9-411f-f2a0-7e1244145871"},"source":["metrics_mlp_alternativo = []\n","print(f'Treinamento do modelo alternativo:', end=' ')\n","\n","for i in range(1, N+1):\n","\n","    mlp_alternativo = keras.models.Sequential([\n","          # Modelo\n","    ])\n","\n","    mlp_alternativo.compile(loss='sparse_categorical_crossentropy', optimizer=best_optimizer, metrics=['accuracy'])\n","    mlp_alternativo.fit(X_train, y_train, batch_size=32, validation_data=(X_valid, y_valid), epochs=5, verbose=False)\n","\n","    loss_t, acc_t = mlp_alternativo.evaluate(X_train, y_train, verbose=False)\n","    loss_v, acc_v = mlp_alternativo.evaluate(X_valid, y_valid, verbose=False)\n","    metrics_mlp_alternativo.append((loss_t, acc_t, loss_v, acc_v))\n","\n","print(f'Finalizado')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Treinamento do modelo alternativo: Finalizado\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2UlWT9tYychB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1600181488540,"user_tz":180,"elapsed":1084,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq9qh4ASVJhDN7nAE9xOe5vneq8826NC9rPKlCRw=s64","userId":"04886257781986524516"}},"outputId":"03f7eecc-5b59-422b-f2d8-dbb249c49fa6"},"source":["metrics_mlp_enunciado = np.array(metrics_mlp_enunciado)\n","metrics_mlp_enunciado_mean = np.reshape(np.mean(metrics_mlp_enunciado, axis=0), (1, 4))\n","\n","metrics_mlp_alternativo = np.array(metrics_mlp_alternativo)\n","metrics_mlp_alternativo_mean = np.reshape(np.mean(metrics_mlp_alternativo, axis=0), (1, 4))\n","\n","metrics_mean = metrics_mlp_enunciado_mean.copy()\n","metrics_mean = np.append(metrics_mean, metrics_mlp_alternativo_mean, axis=0)\n","\n","df = pd.DataFrame(metrics_mean, columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_acc'], index=['Modelo proposto', 'Modelo alternativo'])\n","df"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Train_loss</th>\n","      <th>Train_acc</th>\n","      <th>Val_loss</th>\n","      <th>Val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Modelo proposto</th>\n","      <td>0.037401</td>\n","      <td>0.988433</td>\n","      <td>0.080994</td>\n","      <td>0.976217</td>\n","    </tr>\n","    <tr>\n","      <th>Modelo alternativo</th>\n","      <td>0.034220</td>\n","      <td>0.989327</td>\n","      <td>0.082900</td>\n","      <td>0.976150</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Train_loss  Train_acc  Val_loss   Val_acc\n","Modelo proposto       0.037401   0.988433  0.080994  0.976217\n","Modelo alternativo    0.034220   0.989327  0.082900  0.976150"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"In9otJ6CydLw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pi6SoFnJxQhE","colab_type":"text"},"source":["# **Exercício de Fixação de Conceitos 2 - Questão 4**\n","\n","### **Enunciado**:\n","- Tomando o mesmo problema de classificação de dados da base MNIST e novamente usando o *framework* Keras, tendo o TensorFlow como *backend*, realize o treinamento de uma rede neural com camadas convolucionais, usando *maxpooling* e *dropout*.\n","- Mais uma vez, é apresentada a seguir uma sugestão de código e de configuração de hiperparâmetros que pode ser tomada como ponto de partida.\n","- A sua proposta deve superar, em termos de desempenho médio, essa sugestão fornecida abaixo.\n","- Descreva de forma objetiva o caminho trilhado até sua configuração final de código.\n","- Compare os resultados (em termos de taxa de acerto de classificação) com aqueles obtidos pelos três tipos de máquinas de aprendizado adotadas nas atividades anteriores (classificador linear, ELM e MLP).\n"]},{"cell_type":"code","metadata":{"id":"mWi9sLEdJhiq","colab_type":"code","colab":{}},"source":["x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lS3j4u0Xw0Jd","colab_type":"text"},"source":["### **Parte 1 - Solução do exercício:**\n","- Diferente do que foi feito na questão 2, onde treinamos 5 redes neurais para cada configuração de hiperparâmetros, aqui são treinadas apenas 3 redes, pois o tempo de treinamento de uma rede convolucional é muito maior que de uma simples rede MLP."]},{"cell_type":"markdown","metadata":{"id":"tShSpGwww4H0","colab_type":"text"},"source":["**a) Arquitetura e treinamento propostos no enunciado:**\n","- Arquitetura:\n","  - Uma camada convolucional com 32 kernels de dimensão 3x3, stride (1,1) e com funções de ativação ReLU.\n","  - Uma segunda camada convolucional com 64 kernels de dimensão 3x3, stride (1,1) e com funções de ativação ReLU, MaxPooling de dimensão 2x2 e taxa de ocorrência de dropout de 25%.\n","  - Camada do tipo Flatten\n","  - Camada fully-connected com 128 neurônios com função de ativação ReLU e taxa de ocorrência de dropout de 50%.\n","  - Uma camada de saída com 10 neurônios com função de ativação softmax (não deve ser alterada).\n","- Treinamento: \n","  - Algoritmo adaptativo Adam, 5 épocas e 32 amostras por mini-batch (default do método fit()).\n","  - Função custo (loss): sparse_categorical_crossentropy (não deve ser alterada).\n","  - Métrica auxiliar: Acurácia (não deve ser alterada).\n","- Resultado do treinamento dos 3 modelos:\n","  - Perdas: 0.0434\n","  - Acurácia: 0.9866"]},{"cell_type":"markdown","metadata":{"id":"jNGq8RS0lwWd","colab_type":"text"},"source":["**b) Alterações na rede convolucional proposta e seus impactos no desempenho:**\n","\n","- A primeira etapa das alterações foi relacionada aos hiperparâmetros da primeira camada convolucional. Foram realizadas as seguintes modificações:\n","  - 1) Redução de 32 para 16 kernels\n","  - 2) Aumento de 32 para 64 kernels\n","  - 3) Redução do tamanho dos kernels de 3x3 para 2x2\n","  - 4) Aumento do tamanho dos kernels de 3x3 para 4x4\n","  - 5) Aumento do stride de (1, 1) para (2, 2)\n","  - 6) Inserção de uma camada de Max Pooling\n","- A Tabela 5 apresenta as métricas de desempenho, perdas e acurácia, para as redes com cada uma das alterações acima.\n","\n","<h><center>Tabela 5: Métricas de desempenho para cada uma das alterações de hiperparâmetros realizadas na primeira camada convolucional.</center></h>\n","\n","| Alteração | Perdas | Acurácia |\n","|-----------------|--------|----------|\n","|1              |0.0421  |0.9871    |\n","|2              |0.0439  |0.9864    |\n","|3              |0.0464  |0.9855    |\n","|4              |0.0409  |0.9873    |\n","|5              |0.0489  |0.9850    |\n","|6              |0.0519  |0.9841    |\n","\n","- Como pode ser observado na Tabela 5, duas alterações levaram a um aumento no desempenho: redução do número de kernels de 32 para 16 e o aumento das dimensões de cada kernel de 3x3 para 4x4.\n","- Diante disso, foram treinadas redes com essas duas alterações juntas visando alcançar um desempenho ainda maior. O resultado dessa investigação está apresentado na Tabela 6. Nota-se que o desempenho dessa configuração foi menor do que o desempenho das redes com cada uma das alterações feitas individualmente.\n","- A segunda parte das alterações foram feitas considerando a primeira camada convolucional com 32 kernels de dimensão 4x4. As modificações, cujo os desempenhos estão apresentados na Tabela 6, foram:\n","  - 7) Remoção da camada de Max Pooling da segunda camada convolucional\n","  - 8) Remoção da camada fully-connected.  \n","\n","<h><center>Tabela 6: Métricas de desempenho para a segunda parte de alterações realizadas na rede convolucional.</center></h>\n","\n","| Alteração | Perdas | Acurácia |\n","|---------------|--------|----------|\n","|1+4            |0.0430  |0.9869    |\n","|7              |0.0342  |0.9894    |\n","|8              |0.0239  |0.9924    |\n","|7+8            |0.0158  |0.9949    |\n","\n","- Pode-se observar que as modificações 7 e 8 levaram a um aumento substancial no desempenho da rede, atingindo uma acurácia de 99,49% com as duas alterações feitas conjuntamente.\n"]},{"cell_type":"markdown","metadata":{"id":"9TDwF583yLZ5","colab_type":"text"},"source":["**c) Arquitetura final que supera o desempenho da rede proposta no enunciado:**\n","- Arquitetura:\n","  - Uma camada convolucional com 32 kernels de dimensão 4x4, stride (1,1) e com funções de ativação ReLU.\n","  - Uma segunda camada convolucional com 64 kernels de dimensão 3x3, stride (1,1), com funções de ativação ReLU e taxa de ocorrência de dropout de 25%.\n","  - Camada do tipo Flatten\n","  - Uma camada de saída com 10 neurônios com função de ativação softmax (não deve ser alterada).\n","- Treinamento: \n","  - Algoritmo adaptativo Adam, 5 épocas e 32 amostras por mini-batch (default do método fit()).\n","  - Função custo (loss): sparse_categorical_crossentropy (não deve ser alterada).\n","  - Métrica auxiliar: Acurácia (não deve ser alterada).\n","- Resultado do treinamento dos 3 modelos:\n","  - Perdas: 0.0158\n","  - Acurácia: 0.9949"]},{"cell_type":"code","metadata":{"id":"ZH3pGaqDKv8f","colab_type":"code","colab":{}},"source":["# Rede proposta: 32 kernels na camada 1\n","num_models = 3\n","EPOCHS = 5\n","media_metricas = []\n","\n","lista_metricas = { 'loss': [], 'accuracy': []}\n","metricas = {}\n","\n","for i in range(0, num_models):\n","    CNN = keras.models.Sequential([\n","        keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]),\n","        keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n","        keras.layers.MaxPooling2D(pool_size=(2,2)),\n","        keras.layers.Dropout(0.25),\n","        keras.layers.Flatten(),\n","        keras.layers.Dense(128, activation='relu'),\n","        keras.layers.Dropout(0.5),\n","        keras.layers.Dense(10, activation='softmax')\n","    ])\n","\n","    CNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    history = CNN.fit(x_train, y_train, epochs=5)\n","\n","    lista_metricas['loss'].append(history.history['loss'][-1])\n","    lista_metricas['accuracy'].append(history.history['accuracy'][-1])\n","\n","for key in lista_metricas.keys():\n","    metricas[key] = sum(lista_metricas[key])/len(lista_metricas[key])\n","\n","media_metricas.append(metricas)\n","print(media_metricas)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ij_X7I0iI0ip","colab_type":"code","colab":{}},"source":["# Rede final:\n","num_models = 3\n","EPOCHS = 5\n","media_metricas = []\n","\n","lista_metricas = { 'loss': [], 'accuracy': []}\n","metricas = {}\n","\n","for i in range(0, num_models):\n","    CNN = keras.models.Sequential([\n","        keras.layers.Conv2D(32, kernel_size=(4, 4), activation='relu', input_shape=x_train.shape[1:]),\n","        keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n","        keras.layers.Dropout(0.25),\n","        keras.layers.Flatten(),\n","        keras.layers.Dense(10, activation='softmax')\n","    ])\n","\n","    CNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    history = CNN.fit(x_train, y_train, epochs=5)\n","\n","    lista_metricas['loss'].append(history.history['loss'][-1])\n","    lista_metricas['accuracy'].append(history.history['accuracy'][-1])\n","\n","for key in lista_metricas.keys():\n","    metricas[key] = sum(lista_metricas[key])/len(lista_metricas[key])\n","\n","media_metricas.append(metricas)\n","print(media_metricas)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c8CHo4314xvd","colab_type":"text"},"source":["### **Parte 2 - Comparação de todos os modelos:**\n","\n","- A Tabela 7 apresenta os desempenhos dos 4 classificadores estudados nas questões 1 a 4.\n","- Classificador Linear:\n","  - Coeficiente de Regularização: 965.8832\n","  - Critério de quadrados mínimos\n","- Máquina de Aprendizado Extremo:\n","  - Camada intermediária: 1000 neurônios com função de ativação ReLU com pesos definidos aleatoriamente de acordo com uma função de distribuição normal com média nula e desvio padrão de 0.2.\n","  - Camada de saída: 10 neurônios com função de ativação linear.\n","  - Critério de quadrados mínimos\n","- Redes MLP e convolucional: estruturas já apresentados neste *notebook* (item f da questão 3 e item c da questão 4, respectivamente).  \n","\n","<h><center>Tabela 7: Desempenho dos 4 modelos de classificadores obtidos nos exercícios dos EFCs 1 e 2 junto aos dados de treinamento.</center></h>\n","\n","| Modelo de Classificador  | Acurácia | Parâmetros ajustáveis |\n","|-------------------------------|----------|------------------|\n","|Linear                         |0.8570    |  7850            |\n","|Máquina de Aprendizado Extremo |0.9456    | 10010            |\n","|Rede MLP                       |0.9887    |407050            |\n","|Rede Convolucional             |0.9949    |357610            |\n","\n","- Como era esperado, o classificador linear apresentou o pior desempenho dentre os modelos, devido ao número reduzido de parâmetros ajustáveis e a propriedade de gerar apenas fronteiras de decisão lineares para separação das classes.\n","\n","- Na sequência está a máquina de aprendizado extremo, cujo ganho de desempenho deve-se a aplicação de funções de ativação não-lineares nos dados de entrada, tornando o modelo capaz de gerar mapeamentos (e fronteiras de decisão) não-lineares e mais flexibilidade. \n","- No entanto, o desempenho da ELM é inferior ao da rede MLP pois a flexibilidade alcançada pela ELM é menor, sendo consequência do menor número de parâmetros ajustáveis.\n","- Já as redes MLP e convolucional estudadas nesse EFC foram capazes de superar significativamente o desempenho dos modelos anteriores. No caso da MLP foi alcançado um desempenho de 98.87%, enquanto a rede convolucional atingiu 99.49%.\n","- Podemos dizer que o alto desempenho da rede MLP deve-se ao elevado nível de flexibilidade do modelo devido ao seu número elevado de parâmetros ajustáveis.\n","- Por outro lado, o desempenho alcançado pela rede convolucional deve-se às camadas convolucionais e suas propriedades, tais como:\n","  - A rede convolucional não requer a vetorização das imagens de entrada.\n","  - Leva em conta o caráter espacial das imagens.\n","  - Há uma redução significativa do número de parâmetros ajustáveis, pois as camadas convolucionais realizam compartilhamento de pesos (as duas camadas convolucionais juntas possuem apenas 19040 pesos sinápticos).\n","  - Maior capacidade de extração de atributos pelos filtros convolucionais.\n","\n","\n","\n"]}]}