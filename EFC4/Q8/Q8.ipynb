{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Q8.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hFi1P1DT4FgS","colab_type":"text"},"source":["# IA353 - Redes Neurais\n","# EFC4 - Questão 8\n","# Solving a Maze with Deep Reinforcement Learning\n","\n","##### **Based on https://www.samyzaf.com/ML/rl/qmaze.html**\n","\n","**Professor:** Fernando J. Von Zuben\n","\n","**Aluno(a)**: Guilherme Rosa\n"]},{"cell_type":"markdown","metadata":{"id":"rjhi5kdG4FgT","colab_type":"text"},"source":["### **1. Importações**"]},{"cell_type":"code","metadata":{"id":"-aDpGQDz4Fg0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341052,"user_tz":180,"elapsed":996,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["from __future__ import print_function\n","from time import sleep\n","from IPython import display\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","from keras.optimizers import SGD , Adam, RMSprop\n","from keras.layers.advanced_activations import PReLU\n","\n","import pylab as pl\n","import os, sys, time, datetime, json, random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnE4WYw0jafw","colab_type":"text"},"source":["### **2. Definições**"]},{"cell_type":"markdown","metadata":{"id":"Or617pq-3heP","colab_type":"text"},"source":["#### **2.1. Definição de alguns parâmetros e do conjunto de ações do agente:**"]},{"cell_type":"code","metadata":{"id":"JQs4V1wY_jJS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341489,"user_tz":180,"elapsed":1382,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n","rat_mark = 0.5      # The current rat cell will be painted by gray 0.5\n","LEFT = 0\n","UP = 1\n","RIGHT = 2\n","DOWN = 3\n","\n","# Actions dictionary\n","actions_dict = {\n","    LEFT: 'left',\n","    UP: 'up',\n","    RIGHT: 'right',\n","    DOWN: 'down',\n","}\n","\n","num_actions = len(actions_dict)\n","\n","# Exploration factor\n","epsilon = 0.1"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SArn4jxu3-QP","colab_type":"text"},"source":["#### **2.2. Definição da classe *Qmaze*:**"]},{"cell_type":"code","metadata":{"id":"d1gPgFfQAMu_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341862,"user_tz":180,"elapsed":1726,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["# maze is a 2d Numpy array of floats between 0.0 to 1.0\n","# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n","# rat = (row, col) initial rat position (defaults to (0,0))\n","\n","class Qmaze(object):\n","\n","    def __init__(self, maze, rat=(0,0)):\n","        self._maze = np.array(maze)   # maze's array\n","        nrows, ncols = self._maze.shape\n","        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n","        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n","        self.free_cells.remove(self.target)\n","        if self._maze[self.target] == 0.0:\n","            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n","        if not rat in self.free_cells:\n","            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n","        self.reset(rat)\n","\n","    def reset(self, rat):\n","        self.rat = rat\n","        self.maze = np.copy(self._maze)\n","        nrows, ncols = self.maze.shape\n","        row, col = rat\n","        self.maze[row, col] = rat_mark\n","        self.state = (row, col, 'start')  # ESTADO = Posição do rato \n","        self.min_reward = -0.5 * self.maze.size\n","        self.total_reward = 0\n","        self.visited = set()  # salva a trajetória do rato\n","\n","    def valid_actions(self, cell=None):\n","\n","        # (row, col) fornece a posição atual (estado) do rato\n","        if cell is None:\n","            row, col, mode = self.state\n","        else:\n","            row, col = cell\n","\n","        actions = [0, 1, 2, 3] # todas as ações possíveis\n","        nrows, ncols = self.maze.shape\n","\n","        if row == 0:\n","            actions.remove(1)  # se o rato está na primeira linha, a ação \"UP\" não é válida\n","        elif row == nrows-1:\n","            actions.remove(3)  # se o rato está na última linha, a ação \"DOWN\" não é válida\n","\n","        if col == 0:\n","            actions.remove(0)  # se o rato está na primeira coluna, a ação \"LEFT\" não é válida\n","        elif col == ncols-1:\n","            actions.remove(2)  # se o rato está na última coluna, a ação \"RIGHT\" não é válida\n","\n","        if row>0 and self.maze[row-1,col] == 0.0:\n","            actions.remove(1)  # se a célula acima estiver bloqueada, a ação \"UP\" não é válida\n","        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n","            actions.remove(3)  # se a célula abaixo estiver bloqueada, a ação \"DOWN\" não é válida\n","\n","        if col>0 and self.maze[row,col-1] == 0.0:\n","            actions.remove(0)  # se a célula à esquerda estiver bloqueada, a ação \"LEFT\" não é válida\n","        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n","            actions.remove(2)  # se a célula à direita estiver bloqueada, a ação \"RIGHT\" não é válida\n","\n","        return actions\n","\n","    def act(self, action):\n","        self.update_state(action)\n","        reward = self.get_reward()\n","        self.total_reward += reward\n","        status = self.game_status()\n","        envstate = self.observe()\n","        return envstate, reward, status\n","\n","    def update_state(self, action):\n","        nrows, ncols = self.maze.shape\n","        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n","\n","        if self.maze[rat_row, rat_col] > 0.0:\n","            self.visited.add((rat_row, rat_col))  # mark visited cell \n","\n","        valid_actions = self.valid_actions()\n","                \n","        if not valid_actions:\n","            nmode = 'blocked'\n","        elif action in valid_actions:\n","            nmode = 'valid'\n","            if action == LEFT:\n","                ncol -= 1\n","            elif action == UP:\n","                nrow -= 1\n","            if action == RIGHT:\n","                ncol += 1\n","            elif action == DOWN:\n","                nrow += 1\n","        else:                  # invalid action, no change in rat position\n","            mode = 'invalid'\n","\n","        # new state\n","        self.state = (nrow, ncol, nmode)\n","\n","    def get_reward(self):\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        \n","        if rat_row == nrows-1 and rat_col == ncols-1: # Alcançou o objetivo (pegar o queijo)\n","            return 1.0\n","        if mode == 'blocked': # Se não há ações válidas - Fim do jogo\n","            return self.min_reward - 1\n","        if (rat_row, rat_col) in self.visited: # Se o rato retornou para uma posição já visitada -> Penalização de -0.25 (Evitar repetição)\n","            return -0.25\n","        if mode == 'invalid': # Se o rato tomou uma ação inválida -> Penalização de -0.75\n","            return -0.75\n","        if mode == 'valid': # Se o rato tomou uma ação válida -> Penalização de -0.04 (Estimula o rato a encontrar o menor caminho entre a posição inicial e o queijo)\n","            return -0.04\n","\n","    def game_status(self):\n","        if self.total_reward < self.min_reward:\n","            return 'lose'\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 'win'\n","\n","        return 'not_over'\n","\n","    def draw_env(self):\n","        canvas = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        # clear all visual marks\n","        for r in range(nrows):\n","            for c in range(ncols):\n","                if canvas[r,c] > 0.0:\n","                    canvas[r,c] = 1.0\n","        # draw the rat\n","        row, col, valid = self.state\n","        canvas[row, col] = rat_mark\n","        return canvas\n","\n","    def observe(self):\n","        canvas = self.draw_env()\n","        envstate = canvas.reshape((1, -1))\n","        return envstate"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJ8y8tyz4GhP","colab_type":"text"},"source":["#### **2.3. Definição da função que apresenta a figura do labirinto em um dado estado:**"]},{"cell_type":"code","metadata":{"id":"ZEgvv0QHAcqO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341863,"user_tz":180,"elapsed":1698,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["def show(qmaze):\n","    \n","    plt.grid('on')\n","    nrows, ncols = qmaze.maze.shape\n","    \n","    ax = plt.gca()\n","    ax.set_xticks(np.arange(0.5, nrows, 1))\n","    ax.set_yticks(np.arange(0.5, ncols, 1))\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    \n","    canvas = np.copy(qmaze.maze)\n","    for row,col in qmaze.visited:\n","        canvas[row,col] = 0.6\n","    rat_row, rat_col, _ = qmaze.state\n","    canvas[rat_row, rat_col] = 0.3   # rat cell\n","    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n","    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n","    return img"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0v6tPGf74fif","colab_type":"text"},"source":["##### **2.3.1. Exemplo I:**"]},{"cell_type":"code","metadata":{"id":"2PTTplH_Am9F","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341864,"user_tz":180,"elapsed":1664,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["maze = np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4IhfsbQPPEg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1595181341865,"user_tz":180,"elapsed":1635,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"901dfdf3-9981-44fd-ffdf-cfbc377c4cf8"},"source":["qmaze = Qmaze(maze)\n","canvas, reward, game_over = qmaze.act(DOWN)\n","print(\"reward=\", reward)\n","show(qmaze)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["reward= -0.04\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9ec4550f28>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"D1dbmpztPdGS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1595181341865,"user_tz":180,"elapsed":1615,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"77ed3abc-b58c-45d5-faa7-dd8a935302ab"},"source":["qmaze.act(DOWN)  # move down\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(UP)  # move up\n","qmaze.act(RIGHT)  # move right\n","show(qmaze)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9e81be9be0>"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"l0B65uf4Pnal","colab_type":"text"},"source":["##### **2.3.2. Exemplo II:**"]},{"cell_type":"code","metadata":{"id":"nXYrCEK_EZ-U","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181341866,"user_tz":180,"elapsed":1572,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["maze = np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n","    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n","])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTO46kedArMF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1595181342282,"user_tz":180,"elapsed":1948,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"2e7b37ab-b757-4232-aa14-93ad5dac9499"},"source":["qmaze = Qmaze(maze)\n","canvas, reward, game_over = qmaze.act(DOWN)\n","print(\"reward=\", reward)\n","show(qmaze)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["reward= -0.04\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9e81b93f60>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"5QOkRblSA3IH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1595181342283,"user_tz":180,"elapsed":1917,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"e624c142-690d-4c64-d601-e79f13d61a74"},"source":["qmaze.act(DOWN)  # move down\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(UP)  # move up\n","show(qmaze)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9e81b82eb8>"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"UqROZ0Rf5BHG","colab_type":"text"},"source":["#### **2.4. Definição da função *play_game*:**"]},{"cell_type":"code","metadata":{"id":"5Qj1TKfnA9qu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181342283,"user_tz":180,"elapsed":1877,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["def play_game(model, qmaze, rat_cell):\n","  \n","    qmaze.reset(rat_cell)\n","    envstate = qmaze.observe()\n","\n","    while True:\n","        prev_envstate = envstate\n","        # get next action\n","        q = model.predict(prev_envstate)\n","        action = np.argmax(q[0])\n","\n","        # apply action, get rewards and new state\n","        envstate, reward, game_status = qmaze.act(action)\n","        if game_status == 'win':\n","            return True\n","        elif game_status == 'lose':\n","            return False"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3oWufVQO5Dzh","colab_type":"text"},"source":["#### **2.5. Definição da função *completion_check*:**"]},{"cell_type":"code","metadata":{"id":"zw53DdHQBKF0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181342284,"user_tz":180,"elapsed":1860,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["def completion_check(model, qmaze):\n","\n","    for cell in qmaze.free_cells:\n","        if not qmaze.valid_actions(cell):\n","            return False\n","        if not play_game(model, qmaze, cell):\n","            return False\n","    \n","    return True"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFIKhkp75FyB","colab_type":"text"},"source":["#### **2.6. Definição da classe *Experience*:**"]},{"cell_type":"code","metadata":{"id":"Bm9WstgwBgjg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181342285,"user_tz":180,"elapsed":1821,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["class Experience(object):\n","  \n","    def __init__(self, model, max_memory=100, discount=0.95):\n","        self.model = model\n","        self.max_memory = max_memory\n","        self.discount = discount\n","        self.memory = list()\n","        self.num_actions = model.output_shape[-1]\n","\n","    def remember(self, episode):\n","        # episode = [envstate, action, reward, envstate_next, game_over]\n","        # memory[i] = episode\n","        # envstate == flattened 1d maze cells info, including rat cell (see method: observe)\n","        self.memory.append(episode)\n","        if len(self.memory) > self.max_memory:\n","            del self.memory[0]\n","\n","    def predict(self, envstate):\n","        return self.model.predict(envstate)[0]\n","\n","    def get_data(self, data_size=10):\n","        env_size = self.memory[0][0].shape[1]   # envstate 1d size (1st element of episode)\n","        mem_size = len(self.memory)\n","        data_size = min(mem_size, data_size)\n","        inputs = np.zeros((data_size, env_size))\n","        targets = np.zeros((data_size, self.num_actions))\n","        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n","            envstate, action, reward, envstate_next, game_over = self.memory[j]\n","            inputs[i] = envstate\n","            # There should be no target values for actions not taken.\n","            targets[i] = self.predict(envstate)\n","            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n","            Q_sa = np.max(self.predict(envstate_next))\n","            if game_over:\n","                targets[i, action] = reward\n","            else:\n","                # reward + gamma * max_a' Q(s', a')\n","                targets[i, action] = reward + self.discount * Q_sa\n","        return inputs, targets"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4JPUl_D5OM8","colab_type":"text"},"source":["#### **2.7. Definição da função de treinamento *qtrain*:**"]},{"cell_type":"code","metadata":{"id":"-QvK92JaBiL7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181342285,"user_tz":180,"elapsed":1800,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["def qtrain(model, maze, **opt):\n","    global epsilon\n","    n_epoch = opt.get('n_epoch', 15000)\n","    max_memory = opt.get('max_memory', 1000)\n","    data_size = opt.get('data_size', 50)\n","    weights_file = opt.get('weights_file', \"\")\n","    name = opt.get('name', 'model')\n","    start_time = datetime.datetime.now()\n","\n","    # If you want to continue training from a previous model,\n","    # just supply the h5 file name to weights_file option\n","    if weights_file:\n","        print(\"loading weights from file: %s\" % (weights_file,))\n","        model.load_weights(weights_file)\n","\n","    # Construct environment/game from numpy array: maze (see above)\n","    qmaze = Qmaze(maze)\n","\n","    # Initialize experience replay object\n","    experience = Experience(model, max_memory=max_memory)\n","\n","    win_history = []   # history of win/lose game\n","    n_free_cells = len(qmaze.free_cells)\n","    hsize = qmaze.maze.size//2   # history window size\n","    win_rate = 0.0\n","    imctr = 1\n","\n","    for epoch in range(n_epoch):     \n","        loss = 0.0\n","        rat_cell = random.choice(qmaze.free_cells)\n","        qmaze.reset(rat_cell)\n","        game_over = False\n","\n","        # get initial envstate (1d flattened canvas)\n","        envstate = qmaze.observe()\n","\n","        n_episodes = 0\n","        while not game_over:\n","            valid_actions = qmaze.valid_actions()\n","            if not valid_actions: break\n","            prev_envstate = envstate\n","            # Get next action\n","            if np.random.rand() < epsilon:\n","                action = random.choice(valid_actions)\n","            else:\n","                action = np.argmax(experience.predict(prev_envstate))\n","\n","            # Apply action, get reward and new envstate\n","            envstate, reward, game_status = qmaze.act(action)\n","            if game_status == 'win':\n","                win_history.append(1)\n","                game_over = True\n","            elif game_status == 'lose':\n","                win_history.append(0)\n","                game_over = True\n","            else:\n","                game_over = False\n","\n","            # Store episode (experience)\n","            episode = [prev_envstate, action, reward, envstate, game_over]\n","            experience.remember(episode)\n","            n_episodes += 1\n","\n","            # Train neural network model\n","            inputs, targets = experience.get_data(data_size=data_size)\n","            h = model.fit(\n","                inputs,\n","                targets,\n","                epochs=8,\n","                batch_size=16,\n","                verbose=0,\n","            )\n","            loss = model.evaluate(inputs, targets, verbose=0)\n","\n","        if len(win_history) > hsize:\n","            win_rate = sum(win_history[-hsize:]) / hsize\n","    \n","        dt = datetime.datetime.now() - start_time\n","        t = format_time(dt.total_seconds())\n","        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n","        print(template.format(epoch, n_epoch-1, loss, n_episodes, sum(win_history), win_rate, t))\n","        # we simply check if training has exhausted all free cells and if in all\n","        # cases the agent won\n","        if win_rate > 0.9 : epsilon = 0.05\n","        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n","            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n","            break\n","\n","    # Save trained model weights and architecture, this will be used by the visualization code\n","    h5file = name + \".h5\"\n","    json_file = name + \".json\"\n","    model.save_weights(h5file, overwrite=True)\n","    with open(json_file, \"w\") as outfile:\n","        json.dump(model.to_json(), outfile)\n","    end_time = datetime.datetime.now()\n","    dt = datetime.datetime.now() - start_time\n","    seconds = dt.total_seconds()\n","    t = format_time(seconds)\n","    print('files: %s, %s' % (h5file, json_file))\n","    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n","    return seconds\n","\n","# This is a small utility for printing readable time strings:\n","def format_time(seconds):\n","    if seconds < 400:\n","        s = float(seconds)\n","        return \"%.1f seconds\" % (s,)\n","    elif seconds < 4000:\n","        m = seconds / 60.0\n","        return \"%.2f minutes\" % (m,)\n","    else:\n","        h = seconds / 3600.0\n","        return \"%.2f hours\" % (h,)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vuK3_VZ45Upm","colab_type":"text"},"source":["#### **2.8. Definição da função de construção da rede neural *build_model*:**"]},{"cell_type":"code","metadata":{"id":"7W6tHgyyBzrr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595181344837,"user_tz":180,"elapsed":960,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}}},"source":["def build_model(maze, lr=0.001):\n","    model = Sequential()\n","    model.add(Dense(maze.size, input_shape=(maze.size,)))\n","    model.add(PReLU())\n","    model.add(Dense(maze.size))\n","    model.add(PReLU())\n","    model.add(Dense(num_actions))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Z1tcn6nYzYN","colab_type":"text"},"source":["### **3. Atividades práticas:**"]},{"cell_type":"markdown","metadata":{"id":"b8g9KTJbY-PO","colab_type":"text"},"source":["#### **3.1. Execute o *notebook* para os dois labirintos propostos (execuções independentes, usando um de cada vez), apresentando os resultados do treinamento até a convergência, além de dois percursos para cada caso de estudo (com condições iniciais distintas), obtidos com a rede neural treinada.**"]},{"cell_type":"markdown","metadata":{"id":"p9l565YyZxQA","colab_type":"text"},"source":["##### **3.1.1. Execução para o labirinto proposto I:**"]},{"cell_type":"markdown","metadata":{"id":"VNfvmYHBbT2Z","colab_type":"text"},"source":["- **Labirinto:**"]},{"cell_type":"code","metadata":{"id":"gUWPPKi6B5tj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1595172873550,"user_tz":180,"elapsed":2850,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"8ab13fd7-172e-41d0-9917-a70c2c7396d8"},"source":["maze1 =  np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n","    [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n","    [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n","    [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","])\n","\n","qmaze1 = Qmaze(maze1)\n","show(qmaze1)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2f3e649be0>"]},"metadata":{"tags":[]},"execution_count":16},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"93JBUdAkbYTI","colab_type":"text"},"source":["- **Treinamento e resultados:**"]},{"cell_type":"code","metadata":{"id":"5H-sJBODaBaq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595173485072,"user_tz":180,"elapsed":614337,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"9c21c923-4104-4866-a84a-c7468c3154da"},"source":["model1 = build_model(maze1)\n","qtrain(model1, maze1, epochs=1000, max_memory=8*maze1.size, data_size=32)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch: 000/14999 | Loss: 0.0010 | Episodes: 108 | Win count: 0 | Win rate: 0.000 | time: 13.5 seconds\n","Epoch: 001/14999 | Loss: 0.0017 | Episodes: 107 | Win count: 0 | Win rate: 0.000 | time: 27.7 seconds\n","Epoch: 002/14999 | Loss: 0.0035 | Episodes: 104 | Win count: 0 | Win rate: 0.000 | time: 41.8 seconds\n","Epoch: 003/14999 | Loss: 0.0308 | Episodes: 104 | Win count: 0 | Win rate: 0.000 | time: 56.1 seconds\n","Epoch: 004/14999 | Loss: 0.0599 | Episodes: 105 | Win count: 0 | Win rate: 0.000 | time: 70.3 seconds\n","Epoch: 005/14999 | Loss: 0.0011 | Episodes: 103 | Win count: 0 | Win rate: 0.000 | time: 83.8 seconds\n","Epoch: 006/14999 | Loss: 0.1173 | Episodes: 4 | Win count: 1 | Win rate: 0.000 | time: 84.3 seconds\n","Epoch: 007/14999 | Loss: 0.0870 | Episodes: 101 | Win count: 1 | Win rate: 0.000 | time: 97.6 seconds\n","Epoch: 008/14999 | Loss: 0.0032 | Episodes: 108 | Win count: 1 | Win rate: 0.000 | time: 112.1 seconds\n","Epoch: 009/14999 | Loss: 0.0015 | Episodes: 105 | Win count: 1 | Win rate: 0.000 | time: 126.0 seconds\n","Epoch: 010/14999 | Loss: 0.0021 | Episodes: 101 | Win count: 1 | Win rate: 0.000 | time: 139.4 seconds\n","Epoch: 011/14999 | Loss: 0.0033 | Episodes: 23 | Win count: 2 | Win rate: 0.000 | time: 142.5 seconds\n","Epoch: 012/14999 | Loss: 0.0423 | Episodes: 1 | Win count: 3 | Win rate: 0.000 | time: 142.6 seconds\n","Epoch: 013/14999 | Loss: 0.0107 | Episodes: 2 | Win count: 4 | Win rate: 0.000 | time: 142.9 seconds\n","Epoch: 014/14999 | Loss: 0.0065 | Episodes: 103 | Win count: 4 | Win rate: 0.000 | time: 156.3 seconds\n","Epoch: 015/14999 | Loss: 0.0077 | Episodes: 104 | Win count: 4 | Win rate: 0.000 | time: 170.1 seconds\n","Epoch: 016/14999 | Loss: 0.0061 | Episodes: 107 | Win count: 4 | Win rate: 0.000 | time: 184.0 seconds\n","Epoch: 017/14999 | Loss: 0.0012 | Episodes: 102 | Win count: 4 | Win rate: 0.000 | time: 197.3 seconds\n","Epoch: 018/14999 | Loss: 0.0017 | Episodes: 105 | Win count: 4 | Win rate: 0.000 | time: 211.1 seconds\n","Epoch: 019/14999 | Loss: 0.0169 | Episodes: 12 | Win count: 5 | Win rate: 0.000 | time: 212.7 seconds\n","Epoch: 020/14999 | Loss: 0.0024 | Episodes: 102 | Win count: 5 | Win rate: 0.000 | time: 226.3 seconds\n","Epoch: 021/14999 | Loss: 0.0050 | Episodes: 102 | Win count: 5 | Win rate: 0.000 | time: 240.0 seconds\n","Epoch: 022/14999 | Loss: 0.0292 | Episodes: 102 | Win count: 5 | Win rate: 0.000 | time: 253.3 seconds\n","Epoch: 023/14999 | Loss: 0.0248 | Episodes: 103 | Win count: 5 | Win rate: 0.000 | time: 267.1 seconds\n","Epoch: 024/14999 | Loss: 0.0370 | Episodes: 104 | Win count: 5 | Win rate: 0.208 | time: 281.8 seconds\n","Epoch: 025/14999 | Loss: 0.0016 | Episodes: 104 | Win count: 5 | Win rate: 0.208 | time: 295.4 seconds\n","Epoch: 026/14999 | Loss: 0.0022 | Episodes: 103 | Win count: 5 | Win rate: 0.208 | time: 308.8 seconds\n","Epoch: 027/14999 | Loss: 0.0026 | Episodes: 16 | Win count: 6 | Win rate: 0.250 | time: 310.9 seconds\n","Epoch: 028/14999 | Loss: 0.0012 | Episodes: 107 | Win count: 6 | Win rate: 0.250 | time: 325.1 seconds\n","Epoch: 029/14999 | Loss: 0.0027 | Episodes: 4 | Win count: 7 | Win rate: 0.292 | time: 325.6 seconds\n","Epoch: 030/14999 | Loss: 0.0032 | Episodes: 7 | Win count: 8 | Win rate: 0.292 | time: 326.6 seconds\n","Epoch: 031/14999 | Loss: 0.0059 | Episodes: 104 | Win count: 8 | Win rate: 0.292 | time: 340.4 seconds\n","Epoch: 032/14999 | Loss: 0.0019 | Episodes: 112 | Win count: 8 | Win rate: 0.292 | time: 356.1 seconds\n","Epoch: 033/14999 | Loss: 0.0015 | Episodes: 107 | Win count: 8 | Win rate: 0.292 | time: 370.2 seconds\n","Epoch: 034/14999 | Loss: 0.0048 | Episodes: 36 | Win count: 9 | Win rate: 0.333 | time: 375.1 seconds\n","Epoch: 035/14999 | Loss: 0.0366 | Episodes: 27 | Win count: 10 | Win rate: 0.333 | time: 378.7 seconds\n","Epoch: 036/14999 | Loss: 0.0045 | Episodes: 51 | Win count: 11 | Win rate: 0.333 | time: 385.4 seconds\n","Epoch: 037/14999 | Loss: 0.0074 | Episodes: 23 | Win count: 12 | Win rate: 0.333 | time: 388.4 seconds\n","Epoch: 038/14999 | Loss: 0.0042 | Episodes: 2 | Win count: 13 | Win rate: 0.375 | time: 388.7 seconds\n","Epoch: 039/14999 | Loss: 0.0049 | Episodes: 8 | Win count: 14 | Win rate: 0.417 | time: 389.8 seconds\n","Epoch: 040/14999 | Loss: 0.0041 | Episodes: 31 | Win count: 15 | Win rate: 0.458 | time: 393.9 seconds\n","Epoch: 041/14999 | Loss: 0.0013 | Episodes: 30 | Win count: 16 | Win rate: 0.500 | time: 397.8 seconds\n","Epoch: 042/14999 | Loss: 0.0012 | Episodes: 10 | Win count: 17 | Win rate: 0.542 | time: 399.1 seconds\n","Epoch: 043/14999 | Loss: 0.0058 | Episodes: 33 | Win count: 18 | Win rate: 0.542 | time: 6.73 minutes\n","Epoch: 044/14999 | Loss: 0.0032 | Episodes: 1 | Win count: 19 | Win rate: 0.583 | time: 6.73 minutes\n","Epoch: 045/14999 | Loss: 0.0019 | Episodes: 5 | Win count: 20 | Win rate: 0.625 | time: 6.74 minutes\n","Epoch: 046/14999 | Loss: 0.0051 | Episodes: 93 | Win count: 21 | Win rate: 0.667 | time: 6.95 minutes\n","Epoch: 047/14999 | Loss: 0.0058 | Episodes: 3 | Win count: 22 | Win rate: 0.708 | time: 6.96 minutes\n","Epoch: 048/14999 | Loss: 0.0018 | Episodes: 30 | Win count: 23 | Win rate: 0.750 | time: 7.02 minutes\n","Epoch: 049/14999 | Loss: 0.0016 | Episodes: 11 | Win count: 24 | Win rate: 0.792 | time: 7.05 minutes\n","Epoch: 050/14999 | Loss: 0.0010 | Episodes: 2 | Win count: 25 | Win rate: 0.833 | time: 7.05 minutes\n","Epoch: 051/14999 | Loss: 0.0114 | Episodes: 21 | Win count: 26 | Win rate: 0.833 | time: 7.10 minutes\n","Epoch: 052/14999 | Loss: 0.0015 | Episodes: 19 | Win count: 27 | Win rate: 0.875 | time: 7.14 minutes\n","Epoch: 053/14999 | Loss: 0.0010 | Episodes: 17 | Win count: 28 | Win rate: 0.875 | time: 7.18 minutes\n","Epoch: 054/14999 | Loss: 0.0065 | Episodes: 25 | Win count: 29 | Win rate: 0.875 | time: 7.23 minutes\n","Epoch: 055/14999 | Loss: 0.0010 | Episodes: 13 | Win count: 30 | Win rate: 0.917 | time: 7.26 minutes\n","Epoch: 056/14999 | Loss: 0.0011 | Episodes: 25 | Win count: 31 | Win rate: 0.958 | time: 7.32 minutes\n","Epoch: 057/14999 | Loss: 0.0039 | Episodes: 6 | Win count: 32 | Win rate: 1.000 | time: 7.33 minutes\n","Epoch: 058/14999 | Loss: 0.0012 | Episodes: 19 | Win count: 33 | Win rate: 1.000 | time: 7.38 minutes\n","Epoch: 059/14999 | Loss: 0.0018 | Episodes: 13 | Win count: 34 | Win rate: 1.000 | time: 7.41 minutes\n","Epoch: 060/14999 | Loss: 0.0016 | Episodes: 23 | Win count: 35 | Win rate: 1.000 | time: 7.46 minutes\n","Epoch: 061/14999 | Loss: 0.0007 | Episodes: 17 | Win count: 36 | Win rate: 1.000 | time: 7.51 minutes\n","Epoch: 062/14999 | Loss: 0.0015 | Episodes: 11 | Win count: 37 | Win rate: 1.000 | time: 7.53 minutes\n","Epoch: 063/14999 | Loss: 0.0008 | Episodes: 10 | Win count: 38 | Win rate: 1.000 | time: 7.56 minutes\n","Epoch: 064/14999 | Loss: 0.0004 | Episodes: 21 | Win count: 39 | Win rate: 1.000 | time: 7.61 minutes\n","Epoch: 065/14999 | Loss: 0.0005 | Episodes: 4 | Win count: 40 | Win rate: 1.000 | time: 7.62 minutes\n","Epoch: 066/14999 | Loss: 0.0016 | Episodes: 3 | Win count: 41 | Win rate: 1.000 | time: 7.63 minutes\n","Epoch: 067/14999 | Loss: 0.0007 | Episodes: 17 | Win count: 42 | Win rate: 1.000 | time: 7.67 minutes\n","Epoch: 068/14999 | Loss: 0.0011 | Episodes: 20 | Win count: 43 | Win rate: 1.000 | time: 7.72 minutes\n","Epoch: 069/14999 | Loss: 0.0003 | Episodes: 3 | Win count: 44 | Win rate: 1.000 | time: 7.73 minutes\n","Epoch: 070/14999 | Loss: 0.0002 | Episodes: 20 | Win count: 45 | Win rate: 1.000 | time: 7.78 minutes\n","Epoch: 071/14999 | Loss: 0.0002 | Episodes: 16 | Win count: 46 | Win rate: 1.000 | time: 7.82 minutes\n","Epoch: 072/14999 | Loss: 0.0006 | Episodes: 25 | Win count: 47 | Win rate: 1.000 | time: 7.87 minutes\n","Epoch: 073/14999 | Loss: 0.0003 | Episodes: 3 | Win count: 48 | Win rate: 1.000 | time: 7.89 minutes\n","Epoch: 074/14999 | Loss: 0.0004 | Episodes: 3 | Win count: 49 | Win rate: 1.000 | time: 7.90 minutes\n","Epoch: 075/14999 | Loss: 0.0004 | Episodes: 15 | Win count: 50 | Win rate: 1.000 | time: 7.94 minutes\n","Epoch: 076/14999 | Loss: 0.0006 | Episodes: 22 | Win count: 51 | Win rate: 1.000 | time: 7.99 minutes\n","Epoch: 077/14999 | Loss: 0.0001 | Episodes: 2 | Win count: 52 | Win rate: 1.000 | time: 8.00 minutes\n","Epoch: 078/14999 | Loss: 0.0005 | Episodes: 25 | Win count: 53 | Win rate: 1.000 | time: 8.06 minutes\n","Epoch: 079/14999 | Loss: 0.0004 | Episodes: 5 | Win count: 54 | Win rate: 1.000 | time: 8.07 minutes\n","Epoch: 080/14999 | Loss: 0.0048 | Episodes: 22 | Win count: 55 | Win rate: 1.000 | time: 8.13 minutes\n","Epoch: 081/14999 | Loss: 0.0002 | Episodes: 14 | Win count: 56 | Win rate: 1.000 | time: 8.16 minutes\n","Epoch: 082/14999 | Loss: 0.0000 | Episodes: 24 | Win count: 57 | Win rate: 1.000 | time: 8.22 minutes\n","Epoch: 083/14999 | Loss: 0.0011 | Episodes: 15 | Win count: 58 | Win rate: 1.000 | time: 8.25 minutes\n","Epoch: 084/14999 | Loss: 0.0003 | Episodes: 17 | Win count: 59 | Win rate: 1.000 | time: 8.29 minutes\n","Epoch: 085/14999 | Loss: 0.0002 | Episodes: 17 | Win count: 60 | Win rate: 1.000 | time: 8.33 minutes\n","Epoch: 086/14999 | Loss: 0.0002 | Episodes: 3 | Win count: 61 | Win rate: 1.000 | time: 8.34 minutes\n","Epoch: 087/14999 | Loss: 0.0002 | Episodes: 9 | Win count: 62 | Win rate: 1.000 | time: 8.36 minutes\n","Epoch: 088/14999 | Loss: 0.0000 | Episodes: 13 | Win count: 63 | Win rate: 1.000 | time: 8.39 minutes\n","Epoch: 089/14999 | Loss: 0.0005 | Episodes: 14 | Win count: 64 | Win rate: 1.000 | time: 8.43 minutes\n","Epoch: 090/14999 | Loss: 0.0001 | Episodes: 3 | Win count: 65 | Win rate: 1.000 | time: 8.43 minutes\n","Epoch: 091/14999 | Loss: 0.0004 | Episodes: 8 | Win count: 66 | Win rate: 1.000 | time: 8.45 minutes\n","Epoch: 092/14999 | Loss: 0.0005 | Episodes: 6 | Win count: 67 | Win rate: 1.000 | time: 8.47 minutes\n","Epoch: 093/14999 | Loss: 0.0000 | Episodes: 38 | Win count: 68 | Win rate: 1.000 | time: 8.56 minutes\n","Epoch: 094/14999 | Loss: 0.0001 | Episodes: 3 | Win count: 69 | Win rate: 1.000 | time: 8.56 minutes\n","Epoch: 095/14999 | Loss: 0.0004 | Episodes: 12 | Win count: 70 | Win rate: 1.000 | time: 8.59 minutes\n","Epoch: 096/14999 | Loss: 0.0004 | Episodes: 40 | Win count: 71 | Win rate: 1.000 | time: 8.69 minutes\n","Epoch: 097/14999 | Loss: 0.0003 | Episodes: 16 | Win count: 72 | Win rate: 1.000 | time: 8.72 minutes\n","Epoch: 098/14999 | Loss: 0.0006 | Episodes: 25 | Win count: 73 | Win rate: 1.000 | time: 8.78 minutes\n","Epoch: 099/14999 | Loss: 0.0043 | Episodes: 2 | Win count: 74 | Win rate: 1.000 | time: 8.79 minutes\n","Epoch: 100/14999 | Loss: 0.0006 | Episodes: 4 | Win count: 75 | Win rate: 1.000 | time: 8.80 minutes\n","Epoch: 101/14999 | Loss: 0.0004 | Episodes: 4 | Win count: 76 | Win rate: 1.000 | time: 8.81 minutes\n","Epoch: 102/14999 | Loss: 0.0001 | Episodes: 7 | Win count: 77 | Win rate: 1.000 | time: 8.83 minutes\n","Epoch: 103/14999 | Loss: 0.0008 | Episodes: 4 | Win count: 78 | Win rate: 1.000 | time: 8.84 minutes\n","Epoch: 104/14999 | Loss: 0.0006 | Episodes: 10 | Win count: 79 | Win rate: 1.000 | time: 8.86 minutes\n","Epoch: 105/14999 | Loss: 0.0006 | Episodes: 1 | Win count: 80 | Win rate: 1.000 | time: 8.87 minutes\n","Epoch: 106/14999 | Loss: 0.0001 | Episodes: 4 | Win count: 81 | Win rate: 1.000 | time: 8.88 minutes\n","Epoch: 107/14999 | Loss: 0.0001 | Episodes: 4 | Win count: 82 | Win rate: 1.000 | time: 8.89 minutes\n","Epoch: 108/14999 | Loss: 0.0004 | Episodes: 5 | Win count: 83 | Win rate: 1.000 | time: 8.90 minutes\n","Epoch: 109/14999 | Loss: 0.0001 | Episodes: 24 | Win count: 84 | Win rate: 1.000 | time: 8.96 minutes\n","Epoch: 110/14999 | Loss: 0.0004 | Episodes: 10 | Win count: 85 | Win rate: 1.000 | time: 8.98 minutes\n","Epoch: 111/14999 | Loss: 0.0003 | Episodes: 3 | Win count: 86 | Win rate: 1.000 | time: 8.99 minutes\n","Epoch: 112/14999 | Loss: 0.0001 | Episodes: 19 | Win count: 87 | Win rate: 1.000 | time: 9.04 minutes\n","Epoch: 113/14999 | Loss: 0.0001 | Episodes: 14 | Win count: 88 | Win rate: 1.000 | time: 9.07 minutes\n","Epoch: 114/14999 | Loss: 0.0002 | Episodes: 4 | Win count: 89 | Win rate: 1.000 | time: 9.08 minutes\n","Epoch: 115/14999 | Loss: 0.0001 | Episodes: 20 | Win count: 90 | Win rate: 1.000 | time: 9.13 minutes\n","Epoch: 116/14999 | Loss: 0.0003 | Episodes: 22 | Win count: 91 | Win rate: 1.000 | time: 9.18 minutes\n","Epoch: 117/14999 | Loss: 0.0004 | Episodes: 8 | Win count: 92 | Win rate: 1.000 | time: 9.20 minutes\n","Epoch: 118/14999 | Loss: 0.0004 | Episodes: 31 | Win count: 93 | Win rate: 1.000 | time: 9.27 minutes\n","Epoch: 119/14999 | Loss: 0.0004 | Episodes: 4 | Win count: 94 | Win rate: 1.000 | time: 9.28 minutes\n","Epoch: 120/14999 | Loss: 0.0006 | Episodes: 57 | Win count: 95 | Win rate: 1.000 | time: 9.41 minutes\n","Epoch: 121/14999 | Loss: 0.0008 | Episodes: 4 | Win count: 96 | Win rate: 1.000 | time: 9.43 minutes\n","Epoch: 122/14999 | Loss: 0.0004 | Episodes: 2 | Win count: 97 | Win rate: 1.000 | time: 9.43 minutes\n","Epoch: 123/14999 | Loss: 0.0001 | Episodes: 21 | Win count: 98 | Win rate: 1.000 | time: 9.48 minutes\n","Epoch: 124/14999 | Loss: 0.0001 | Episodes: 5 | Win count: 99 | Win rate: 1.000 | time: 9.50 minutes\n","Epoch: 125/14999 | Loss: 0.0001 | Episodes: 2 | Win count: 100 | Win rate: 1.000 | time: 9.50 minutes\n","Epoch: 126/14999 | Loss: 0.0012 | Episodes: 32 | Win count: 101 | Win rate: 1.000 | time: 9.58 minutes\n","Epoch: 127/14999 | Loss: 0.0006 | Episodes: 4 | Win count: 102 | Win rate: 1.000 | time: 9.59 minutes\n","Epoch: 128/14999 | Loss: 0.0005 | Episodes: 5 | Win count: 103 | Win rate: 1.000 | time: 9.60 minutes\n","Epoch: 129/14999 | Loss: 0.0003 | Episodes: 1 | Win count: 104 | Win rate: 1.000 | time: 9.61 minutes\n","Epoch: 130/14999 | Loss: 0.0007 | Episodes: 27 | Win count: 105 | Win rate: 1.000 | time: 9.68 minutes\n","Epoch: 131/14999 | Loss: 0.0008 | Episodes: 9 | Win count: 106 | Win rate: 1.000 | time: 9.70 minutes\n","Epoch: 132/14999 | Loss: 0.0003 | Episodes: 28 | Win count: 107 | Win rate: 1.000 | time: 9.77 minutes\n","Epoch: 133/14999 | Loss: 0.0003 | Episodes: 13 | Win count: 108 | Win rate: 1.000 | time: 9.81 minutes\n","Epoch: 134/14999 | Loss: 0.0008 | Episodes: 18 | Win count: 109 | Win rate: 1.000 | time: 9.86 minutes\n","Epoch: 135/14999 | Loss: 0.0006 | Episodes: 31 | Win count: 110 | Win rate: 1.000 | time: 9.93 minutes\n","Epoch: 136/14999 | Loss: 0.0005 | Episodes: 20 | Win count: 111 | Win rate: 1.000 | time: 9.98 minutes\n","Epoch: 137/14999 | Loss: 0.0005 | Episodes: 4 | Win count: 112 | Win rate: 1.000 | time: 10.00 minutes\n","Epoch: 138/14999 | Loss: 0.0005 | Episodes: 23 | Win count: 113 | Win rate: 1.000 | time: 10.06 minutes\n","Epoch: 139/14999 | Loss: 0.0004 | Episodes: 1 | Win count: 114 | Win rate: 1.000 | time: 10.06 minutes\n","Epoch: 140/14999 | Loss: 0.0004 | Episodes: 24 | Win count: 115 | Win rate: 1.000 | time: 10.12 minutes\n","Epoch: 141/14999 | Loss: 0.0006 | Episodes: 19 | Win count: 116 | Win rate: 1.000 | time: 10.16 minutes\n","Epoch: 142/14999 | Loss: 0.0008 | Episodes: 4 | Win count: 117 | Win rate: 1.000 | time: 10.17 minutes\n","Reached 100% win rate at epoch: 142\n","files: model.h5, model.json\n","n_epoch: 142, max_mem: 392, data: 32, time: 10.18 minutes\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["610.707407"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"thJJDPz8dHdl","colab_type":"text"},"source":["- **Apresentação do percurso realizado pelo modelo com o rato iniciando na posição (1, 1):**"]},{"cell_type":"code","metadata":{"id":"k8Xhre5AdbR2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595173485079,"user_tz":180,"elapsed":614330,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"a659a80e-cc57-4e6b-a4e0-114f0e9f09e9"},"source":["random.seed(a=42)\n","rat_cell1 = random.choice(qmaze1.free_cells)\n","print(f'Posição inicial: {rat_cell1}')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Posição inicial: (1, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oQzL07T7ayIC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595173492955,"user_tz":180,"elapsed":622187,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"5f5cef68-9994-40f2-bd31-16c382882df5"},"source":["qmaze1.reset(rat_cell1)\n","envstate = qmaze1.observe()\n","game_status = 'lose'\n","\n","q_values1 = []\n","rat_positions1 = []\n","\n","while(game_status != 'win'):\n","    q = model1.predict(envstate)\n","    action = np.argmax(q[0])\n","    # action = np.argmax(model.predict(envstate))\n","    rat_status = qmaze1.state # posição do ratinho antes dele atuar no ambiente\n","    envstate, reward, game_status = qmaze1.act(action)\n","\n","    rat_positions1.append(rat_status[:-1])\n","    q_values1.append(q)\n","\n","    show(qmaze1)\n","    display.clear_output(wait=True)\n","    display.display(pl.gcf())\n","    plt.gca().clear()\n","    plt.close()\n","    sleep(0.2)\n","\n","rat_positions1 = list(enumerate(rat_positions1))"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"h4B1Conwdf2g","colab_type":"text"},"source":["- **Apresentação do percurso realizado pelo modelo com o rato iniciando na posição (3, 3):**"]},{"cell_type":"code","metadata":{"id":"Viv-Run8dkne","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595173492957,"user_tz":180,"elapsed":622148,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"5a83f3e3-054e-4d60-c572-c0a42972ae66"},"source":["random.seed(a=13)\n","rat_cell1 = random.choice(qmaze1.free_cells)\n","print(f'Posição inicial: {rat_cell1}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Posição inicial: (3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BgxsXyiVc95a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595173497793,"user_tz":180,"elapsed":626957,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"f5ba874c-e410-4726-c351-affa973fbc64"},"source":["qmaze1.reset(rat_cell1)\n","envstate = qmaze1.observe()\n","game_status = 'lose'\n","\n","while(game_status != 'win'):\n","    q = model1.predict(envstate)\n","    action = np.argmax(q[0])\n","    # action = np.argmax(model.predict(envstate))\n","    envstate, reward, game_status = qmaze1.act(action)\n","    show(qmaze1)\n","    display.clear_output(wait=True)\n","    display.display(pl.gcf())\n","    plt.gca().clear()\n","    plt.close()\n","    sleep(0.2)"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"kZ5nLacGd8Rw","colab_type":"text"},"source":["##### **3.1.2. Execução para o labirinto proposto II:**"]},{"cell_type":"markdown","metadata":{"id":"ddzmYr2GeIou","colab_type":"text"},"source":["- **Labirinto:**"]},{"cell_type":"code","metadata":{"id":"sXIvaUxDE2tE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1595181358972,"user_tz":180,"elapsed":910,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"4e1443a4-e570-444e-ed4d-2c0c1362bd72"},"source":["maze2 = np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n","    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n","])\n","qmaze2 = Qmaze(maze2)\n","show(qmaze2)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9e81ab9f60>"]},"metadata":{"tags":[]},"execution_count":19},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"bHyaUTgfeaP3","colab_type":"text"},"source":["- **Treinamento e resultados:**"]},{"cell_type":"code","metadata":{"id":"wK9lCeTACAcy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595182316579,"user_tz":180,"elapsed":953847,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"da549045-e215-431c-c540-718dd8f5a1f4"},"source":["model2 = build_model(maze2)\n","qtrain(model2, maze2, epochs=1000, max_memory=8*maze2.size, data_size=32)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch: 000/14999 | Loss: 0.0019 | Episodes: 220 | Win count: 0 | Win rate: 0.000 | time: 22.5 seconds\n","Epoch: 001/14999 | Loss: 0.0019 | Episodes: 207 | Win count: 0 | Win rate: 0.000 | time: 42.7 seconds\n","Epoch: 002/14999 | Loss: 0.0607 | Episodes: 218 | Win count: 0 | Win rate: 0.000 | time: 64.2 seconds\n","Epoch: 003/14999 | Loss: 0.0013 | Episodes: 221 | Win count: 0 | Win rate: 0.000 | time: 86.3 seconds\n","Epoch: 004/14999 | Loss: 0.0013 | Episodes: 231 | Win count: 0 | Win rate: 0.000 | time: 109.3 seconds\n","Epoch: 005/14999 | Loss: 0.0012 | Episodes: 218 | Win count: 0 | Win rate: 0.000 | time: 131.0 seconds\n","Epoch: 006/14999 | Loss: 0.0015 | Episodes: 219 | Win count: 0 | Win rate: 0.000 | time: 152.6 seconds\n","Epoch: 007/14999 | Loss: 0.0018 | Episodes: 212 | Win count: 0 | Win rate: 0.000 | time: 173.3 seconds\n","Epoch: 008/14999 | Loss: 0.0010 | Episodes: 61 | Win count: 1 | Win rate: 0.000 | time: 179.1 seconds\n","Epoch: 009/14999 | Loss: 0.0284 | Episodes: 233 | Win count: 1 | Win rate: 0.000 | time: 201.7 seconds\n","Epoch: 010/14999 | Loss: 0.0016 | Episodes: 214 | Win count: 1 | Win rate: 0.000 | time: 223.4 seconds\n","Epoch: 011/14999 | Loss: 0.0092 | Episodes: 114 | Win count: 2 | Win rate: 0.000 | time: 234.8 seconds\n","Epoch: 012/14999 | Loss: 0.0019 | Episodes: 211 | Win count: 2 | Win rate: 0.000 | time: 255.0 seconds\n","Epoch: 013/14999 | Loss: 0.0240 | Episodes: 211 | Win count: 2 | Win rate: 0.000 | time: 275.7 seconds\n","Epoch: 014/14999 | Loss: 0.0016 | Episodes: 38 | Win count: 3 | Win rate: 0.000 | time: 279.4 seconds\n","Epoch: 015/14999 | Loss: 0.0054 | Episodes: 208 | Win count: 3 | Win rate: 0.000 | time: 299.4 seconds\n","Epoch: 016/14999 | Loss: 0.0015 | Episodes: 36 | Win count: 4 | Win rate: 0.000 | time: 302.8 seconds\n","Epoch: 017/14999 | Loss: 0.0069 | Episodes: 211 | Win count: 4 | Win rate: 0.000 | time: 323.8 seconds\n","Epoch: 018/14999 | Loss: 0.0371 | Episodes: 211 | Win count: 4 | Win rate: 0.000 | time: 344.6 seconds\n","Epoch: 019/14999 | Loss: 0.0011 | Episodes: 219 | Win count: 4 | Win rate: 0.000 | time: 365.4 seconds\n","Epoch: 020/14999 | Loss: 0.0520 | Episodes: 209 | Win count: 4 | Win rate: 0.000 | time: 385.6 seconds\n","Epoch: 021/14999 | Loss: 0.0013 | Episodes: 211 | Win count: 4 | Win rate: 0.000 | time: 6.77 minutes\n","Epoch: 022/14999 | Loss: 0.0682 | Episodes: 31 | Win count: 5 | Win rate: 0.000 | time: 6.82 minutes\n","Epoch: 023/14999 | Loss: 0.0729 | Episodes: 225 | Win count: 5 | Win rate: 0.000 | time: 7.18 minutes\n","Epoch: 024/14999 | Loss: 0.0015 | Episodes: 221 | Win count: 5 | Win rate: 0.000 | time: 7.53 minutes\n","Epoch: 025/14999 | Loss: 0.0069 | Episodes: 131 | Win count: 6 | Win rate: 0.000 | time: 7.74 minutes\n","Epoch: 026/14999 | Loss: 0.0026 | Episodes: 211 | Win count: 6 | Win rate: 0.000 | time: 8.09 minutes\n","Epoch: 027/14999 | Loss: 0.0377 | Episodes: 53 | Win count: 7 | Win rate: 0.000 | time: 8.17 minutes\n","Epoch: 028/14999 | Loss: 0.0043 | Episodes: 211 | Win count: 7 | Win rate: 0.000 | time: 8.51 minutes\n","Epoch: 029/14999 | Loss: 0.0152 | Episodes: 47 | Win count: 8 | Win rate: 0.000 | time: 8.59 minutes\n","Epoch: 030/14999 | Loss: 0.0034 | Episodes: 30 | Win count: 9 | Win rate: 0.000 | time: 8.64 minutes\n","Epoch: 031/14999 | Loss: 0.0064 | Episodes: 237 | Win count: 10 | Win rate: 0.000 | time: 9.04 minutes\n","Epoch: 032/14999 | Loss: 0.0131 | Episodes: 119 | Win count: 11 | Win rate: 0.000 | time: 9.23 minutes\n","Epoch: 033/14999 | Loss: 0.0021 | Episodes: 16 | Win count: 12 | Win rate: 0.000 | time: 9.26 minutes\n","Epoch: 034/14999 | Loss: 0.0029 | Episodes: 218 | Win count: 12 | Win rate: 0.000 | time: 9.60 minutes\n","Epoch: 035/14999 | Loss: 0.0032 | Episodes: 211 | Win count: 12 | Win rate: 0.000 | time: 9.95 minutes\n","Epoch: 036/14999 | Loss: 0.0030 | Episodes: 61 | Win count: 13 | Win rate: 0.000 | time: 10.05 minutes\n","Epoch: 037/14999 | Loss: 0.0013 | Episodes: 19 | Win count: 14 | Win rate: 0.000 | time: 10.08 minutes\n","Epoch: 038/14999 | Loss: 0.0057 | Episodes: 218 | Win count: 14 | Win rate: 0.000 | time: 10.43 minutes\n","Epoch: 039/14999 | Loss: 0.0725 | Episodes: 21 | Win count: 15 | Win rate: 0.000 | time: 10.46 minutes\n","Epoch: 040/14999 | Loss: 0.0027 | Episodes: 20 | Win count: 16 | Win rate: 0.000 | time: 10.50 minutes\n","Epoch: 041/14999 | Loss: 0.0025 | Episodes: 15 | Win count: 17 | Win rate: 0.000 | time: 10.52 minutes\n","Epoch: 042/14999 | Loss: 0.0056 | Episodes: 32 | Win count: 18 | Win rate: 0.000 | time: 10.57 minutes\n","Epoch: 043/14999 | Loss: 0.0463 | Episodes: 21 | Win count: 19 | Win rate: 0.000 | time: 10.61 minutes\n","Epoch: 044/14999 | Loss: 0.0180 | Episodes: 67 | Win count: 20 | Win rate: 0.000 | time: 10.72 minutes\n","Epoch: 045/14999 | Loss: 0.0236 | Episodes: 34 | Win count: 21 | Win rate: 0.000 | time: 10.77 minutes\n","Epoch: 046/14999 | Loss: 0.0040 | Episodes: 210 | Win count: 22 | Win rate: 0.000 | time: 11.11 minutes\n","Epoch: 047/14999 | Loss: 0.0048 | Episodes: 29 | Win count: 23 | Win rate: 0.000 | time: 11.16 minutes\n","Epoch: 048/14999 | Loss: 0.0043 | Episodes: 70 | Win count: 24 | Win rate: 0.000 | time: 11.27 minutes\n","Epoch: 049/14999 | Loss: 0.0238 | Episodes: 7 | Win count: 25 | Win rate: 0.000 | time: 11.28 minutes\n","Epoch: 050/14999 | Loss: 0.0027 | Episodes: 7 | Win count: 26 | Win rate: 0.520 | time: 11.29 minutes\n","Epoch: 051/14999 | Loss: 0.0023 | Episodes: 109 | Win count: 27 | Win rate: 0.540 | time: 11.46 minutes\n","Epoch: 052/14999 | Loss: 0.0075 | Episodes: 44 | Win count: 28 | Win rate: 0.560 | time: 11.53 minutes\n","Epoch: 053/14999 | Loss: 0.0366 | Episodes: 212 | Win count: 28 | Win rate: 0.560 | time: 11.88 minutes\n","Epoch: 054/14999 | Loss: 0.0033 | Episodes: 21 | Win count: 29 | Win rate: 0.580 | time: 11.91 minutes\n","Epoch: 055/14999 | Loss: 0.0129 | Episodes: 2 | Win count: 30 | Win rate: 0.600 | time: 11.91 minutes\n","Epoch: 056/14999 | Loss: 0.0051 | Episodes: 7 | Win count: 31 | Win rate: 0.620 | time: 11.93 minutes\n","Epoch: 057/14999 | Loss: 0.0026 | Episodes: 40 | Win count: 32 | Win rate: 0.640 | time: 11.99 minutes\n","Epoch: 058/14999 | Loss: 0.0056 | Episodes: 208 | Win count: 33 | Win rate: 0.640 | time: 12.32 minutes\n","Epoch: 059/14999 | Loss: 0.0192 | Episodes: 21 | Win count: 34 | Win rate: 0.660 | time: 12.36 minutes\n","Epoch: 060/14999 | Loss: 0.0090 | Episodes: 21 | Win count: 35 | Win rate: 0.680 | time: 12.39 minutes\n","Epoch: 061/14999 | Loss: 0.0027 | Episodes: 29 | Win count: 36 | Win rate: 0.680 | time: 12.44 minutes\n","Epoch: 062/14999 | Loss: 0.0041 | Episodes: 105 | Win count: 37 | Win rate: 0.700 | time: 12.61 minutes\n","Epoch: 063/14999 | Loss: 0.0037 | Episodes: 66 | Win count: 38 | Win rate: 0.720 | time: 12.71 minutes\n","Epoch: 064/14999 | Loss: 0.0049 | Episodes: 51 | Win count: 39 | Win rate: 0.720 | time: 12.79 minutes\n","Epoch: 065/14999 | Loss: 0.0054 | Episodes: 19 | Win count: 40 | Win rate: 0.740 | time: 12.82 minutes\n","Epoch: 066/14999 | Loss: 0.0063 | Episodes: 38 | Win count: 41 | Win rate: 0.740 | time: 12.88 minutes\n","Epoch: 067/14999 | Loss: 0.0028 | Episodes: 25 | Win count: 42 | Win rate: 0.760 | time: 12.92 minutes\n","Epoch: 068/14999 | Loss: 0.0024 | Episodes: 61 | Win count: 43 | Win rate: 0.780 | time: 13.02 minutes\n","Epoch: 069/14999 | Loss: 0.0039 | Episodes: 26 | Win count: 44 | Win rate: 0.800 | time: 13.06 minutes\n","Epoch: 070/14999 | Loss: 0.0062 | Episodes: 83 | Win count: 45 | Win rate: 0.820 | time: 13.20 minutes\n","Epoch: 071/14999 | Loss: 0.0034 | Episodes: 31 | Win count: 46 | Win rate: 0.840 | time: 13.24 minutes\n","Epoch: 072/14999 | Loss: 0.0019 | Episodes: 30 | Win count: 47 | Win rate: 0.840 | time: 13.29 minutes\n","Epoch: 073/14999 | Loss: 0.0024 | Episodes: 44 | Win count: 48 | Win rate: 0.860 | time: 13.36 minutes\n","Epoch: 074/14999 | Loss: 0.0013 | Episodes: 40 | Win count: 49 | Win rate: 0.880 | time: 13.43 minutes\n","Epoch: 075/14999 | Loss: 0.0016 | Episodes: 10 | Win count: 50 | Win rate: 0.880 | time: 13.44 minutes\n","Epoch: 076/14999 | Loss: 0.0021 | Episodes: 39 | Win count: 51 | Win rate: 0.900 | time: 13.50 minutes\n","Epoch: 077/14999 | Loss: 0.0018 | Episodes: 48 | Win count: 52 | Win rate: 0.900 | time: 13.58 minutes\n","Epoch: 078/14999 | Loss: 0.0019 | Episodes: 45 | Win count: 53 | Win rate: 0.920 | time: 13.65 minutes\n","Epoch: 079/14999 | Loss: 0.0023 | Episodes: 50 | Win count: 54 | Win rate: 0.920 | time: 13.73 minutes\n","Epoch: 080/14999 | Loss: 0.0035 | Episodes: 45 | Win count: 55 | Win rate: 0.920 | time: 13.81 minutes\n","Epoch: 081/14999 | Loss: 0.0065 | Episodes: 1 | Win count: 56 | Win rate: 0.920 | time: 13.81 minutes\n","Epoch: 082/14999 | Loss: 0.0018 | Episodes: 18 | Win count: 57 | Win rate: 0.920 | time: 13.84 minutes\n","Epoch: 083/14999 | Loss: 0.0010 | Episodes: 7 | Win count: 58 | Win rate: 0.920 | time: 13.85 minutes\n","Epoch: 084/14999 | Loss: 0.0016 | Episodes: 8 | Win count: 59 | Win rate: 0.940 | time: 13.86 minutes\n","Epoch: 085/14999 | Loss: 0.0015 | Episodes: 34 | Win count: 60 | Win rate: 0.960 | time: 13.92 minutes\n","Epoch: 086/14999 | Loss: 0.0019 | Episodes: 25 | Win count: 61 | Win rate: 0.960 | time: 13.96 minutes\n","Epoch: 087/14999 | Loss: 0.0025 | Episodes: 25 | Win count: 62 | Win rate: 0.960 | time: 14.01 minutes\n","Epoch: 088/14999 | Loss: 0.0010 | Episodes: 44 | Win count: 63 | Win rate: 0.980 | time: 14.08 minutes\n","Epoch: 089/14999 | Loss: 0.0005 | Episodes: 3 | Win count: 64 | Win rate: 0.980 | time: 14.09 minutes\n","Epoch: 090/14999 | Loss: 0.0015 | Episodes: 24 | Win count: 65 | Win rate: 0.980 | time: 14.12 minutes\n","Epoch: 091/14999 | Loss: 0.0012 | Episodes: 29 | Win count: 66 | Win rate: 0.980 | time: 14.17 minutes\n","Epoch: 092/14999 | Loss: 0.0017 | Episodes: 61 | Win count: 67 | Win rate: 0.980 | time: 14.27 minutes\n","Epoch: 093/14999 | Loss: 0.0016 | Episodes: 4 | Win count: 68 | Win rate: 0.980 | time: 14.28 minutes\n","Epoch: 094/14999 | Loss: 0.0011 | Episodes: 28 | Win count: 69 | Win rate: 0.980 | time: 14.32 minutes\n","Epoch: 095/14999 | Loss: 0.0012 | Episodes: 31 | Win count: 70 | Win rate: 0.980 | time: 14.37 minutes\n","Epoch: 096/14999 | Loss: 0.0014 | Episodes: 33 | Win count: 71 | Win rate: 0.980 | time: 14.43 minutes\n","Epoch: 097/14999 | Loss: 0.0004 | Episodes: 15 | Win count: 72 | Win rate: 0.980 | time: 14.45 minutes\n","Epoch: 098/14999 | Loss: 0.0010 | Episodes: 4 | Win count: 73 | Win rate: 0.980 | time: 14.46 minutes\n","Epoch: 099/14999 | Loss: 0.0005 | Episodes: 30 | Win count: 74 | Win rate: 0.980 | time: 14.51 minutes\n","Epoch: 100/14999 | Loss: 0.0005 | Episodes: 46 | Win count: 75 | Win rate: 0.980 | time: 14.59 minutes\n","Epoch: 101/14999 | Loss: 0.0005 | Episodes: 21 | Win count: 76 | Win rate: 0.980 | time: 14.62 minutes\n","Epoch: 102/14999 | Loss: 0.0009 | Episodes: 26 | Win count: 77 | Win rate: 0.980 | time: 14.66 minutes\n","Epoch: 103/14999 | Loss: 0.0009 | Episodes: 42 | Win count: 78 | Win rate: 1.000 | time: 14.73 minutes\n","Epoch: 104/14999 | Loss: 0.0006 | Episodes: 36 | Win count: 79 | Win rate: 1.000 | time: 14.81 minutes\n","Epoch: 105/14999 | Loss: 0.0013 | Episodes: 54 | Win count: 80 | Win rate: 1.000 | time: 14.89 minutes\n","Epoch: 106/14999 | Loss: 0.0004 | Episodes: 22 | Win count: 81 | Win rate: 1.000 | time: 14.93 minutes\n","Epoch: 107/14999 | Loss: 0.0005 | Episodes: 19 | Win count: 82 | Win rate: 1.000 | time: 14.96 minutes\n","Epoch: 108/14999 | Loss: 0.0014 | Episodes: 31 | Win count: 83 | Win rate: 1.000 | time: 15.02 minutes\n","Epoch: 109/14999 | Loss: 0.0013 | Episodes: 53 | Win count: 84 | Win rate: 1.000 | time: 15.11 minutes\n","Epoch: 110/14999 | Loss: 0.0005 | Episodes: 18 | Win count: 85 | Win rate: 1.000 | time: 15.14 minutes\n","Epoch: 111/14999 | Loss: 0.0004 | Episodes: 16 | Win count: 86 | Win rate: 1.000 | time: 15.17 minutes\n","Epoch: 112/14999 | Loss: 0.0004 | Episodes: 57 | Win count: 87 | Win rate: 1.000 | time: 15.26 minutes\n","Epoch: 113/14999 | Loss: 0.0006 | Episodes: 32 | Win count: 88 | Win rate: 1.000 | time: 15.31 minutes\n","Epoch: 114/14999 | Loss: 0.0003 | Episodes: 37 | Win count: 89 | Win rate: 1.000 | time: 15.38 minutes\n","Epoch: 115/14999 | Loss: 0.0005 | Episodes: 21 | Win count: 90 | Win rate: 1.000 | time: 15.42 minutes\n","Epoch: 116/14999 | Loss: 0.0009 | Episodes: 63 | Win count: 91 | Win rate: 1.000 | time: 15.52 minutes\n","Epoch: 117/14999 | Loss: 0.0021 | Episodes: 20 | Win count: 92 | Win rate: 1.000 | time: 15.56 minutes\n","Epoch: 118/14999 | Loss: 0.0006 | Episodes: 21 | Win count: 93 | Win rate: 1.000 | time: 15.60 minutes\n","Epoch: 119/14999 | Loss: 0.0004 | Episodes: 38 | Win count: 94 | Win rate: 1.000 | time: 15.66 minutes\n","Epoch: 120/14999 | Loss: 0.0007 | Episodes: 21 | Win count: 95 | Win rate: 1.000 | time: 15.69 minutes\n","Epoch: 121/14999 | Loss: 0.0009 | Episodes: 13 | Win count: 96 | Win rate: 1.000 | time: 15.72 minutes\n","Reached 100% win rate at epoch: 121\n","files: model.h5, model.json\n","n_epoch: 121, max_mem: 800, data: 32, time: 15.75 minutes\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["944.721647"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"efrXSXHTejbf","colab_type":"text"},"source":["- **Apresentação do percurso realizado pelo modelo com o rato iniciando na posição (, ):**"]},{"cell_type":"code","metadata":{"id":"GHJVd9Ide0fW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595182316586,"user_tz":180,"elapsed":911621,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"d6cbbf25-3dfb-4b26-ff29-b94adf63db59"},"source":["random.seed(a=42)\n","rat_cell2 = random.choice(qmaze2.free_cells)\n","print(f'Posição inicial: {rat_cell2}')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Posição inicial: (1, 6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V5R8DdBwe7G7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595182325435,"user_tz":180,"elapsed":918093,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"e4167044-8c3a-46ab-b69d-d3e5dc3322d0"},"source":["qmaze2.reset(rat_cell2)\n","envstate = qmaze2.observe()\n","game_status = 'lose'\n","\n","q_values2 = []\n","rat_positions2 = []\n","\n","while(game_status != 'win'):\n","    q = model2.predict(envstate)\n","    action = np.argmax(q[0])\n","    # action = np.argmax(model.predict(envstate))\n","    rat_status = qmaze2.state # posição do ratinho antes dele atuar no ambiente\n","    envstate, reward, game_status = qmaze2.act(action)\n","\n","    rat_positions2.append(rat_status[:-1])\n","    q_values2.append(q)\n","\n","    show(qmaze2)\n","    display.clear_output(wait=True)\n","    display.display(pl.gcf())\n","    plt.gca().clear()\n","    plt.close()\n","    sleep(0.2)\n","\n","rat_positions2 = list(enumerate(rat_positions2))"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DY4e3-fFeoHH","colab_type":"text"},"source":["- **Apresentação do percurso realizado pelo modelo com o rato iniciando na posição (, ):**"]},{"cell_type":"code","metadata":{"id":"TN8jOQ0afCSZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595182326442,"user_tz":180,"elapsed":981,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"26564c90-5cbf-4e2f-ddaf-8f6011d7901b"},"source":["random.seed(a=13)\n","rat_cell2 = random.choice(qmaze2.free_cells)\n","print(f'Posição inicial: {rat_cell2}')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Posição inicial: (4, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dXvZOJD7fDSq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595182331765,"user_tz":180,"elapsed":6277,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"bf2d2017-2178-4c3f-e7e6-44de1b60514d"},"source":["qmaze2.reset(rat_cell2)\n","envstate = qmaze2.observe()\n","game_status = 'lose'\n","\n","while(game_status != 'win'):\n","  q = model2.predict(envstate)\n","  action = np.argmax(q[0])\n","  # action = np.argmax(model.predict(envstate))\n","  envstate, reward, game_status = qmaze2.act(action)\n","  show(qmaze2)\n","  display.clear_output(wait=True)\n","  display.display(pl.gcf())\n","  plt.gca().clear()\n","  plt.close()\n","  sleep(0.2)"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"GIPqEHr1fwnZ","colab_type":"text"},"source":["#### **3.2. Para esses dois casos de estudo, apresente os 4 valores da função Q-valor para 3 estados representativos do ambiente, produzidos pela rede neural treinada.**"]},{"cell_type":"markdown","metadata":{"id":"W9ks4EUnnMMf","colab_type":"text"},"source":["- **Caso de estudo - Labirinto proposto I (subseção 3.1.1): Apresentação do função Q-valor para 3 estados representativos do ambiente**"]},{"cell_type":"code","metadata":{"id":"2A-A0DORqmSq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595176530552,"user_tz":180,"elapsed":17751,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"0d07e71b-f656-446c-d46b-007f878f1e85"},"source":["qmaze1.reset(rat_positions1[0][1])\n","show(qmaze1);"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"v8XcpH1hn_J3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1595176648046,"user_tz":180,"elapsed":1166,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"07498f22-5efd-4a5b-a96d-b6058e882664"},"source":["for i in range(0, 3):\n","    idx, rat_position = random.choice(list(rat_positions1))\n","    print('-------------------------------------------------------------------')\n","    print(f'Posição do rato: {rat_position}')\n","    print(f'Função Q-valor: {q_values1[idx]}')\n","    print(f'Ação tomada: {actions_dict[np.argmax(q_values1[idx])]}')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["-------------------------------------------------------------------\n","Posição do rato: (0, 5)\n","Função Q-valor: [[-0.43571314 -0.58924776 -0.33554417 -0.27582842]]\n","Ação tomada: down\n","-------------------------------------------------------------------\n","Posição do rato: (5, 3)\n","Função Q-valor: [[0.20439735 0.46279466 0.75450486 0.33679938]]\n","Ação tomada: right\n","-------------------------------------------------------------------\n","Posição do rato: (2, 5)\n","Função Q-valor: [[-0.25152257 -0.6023271  -0.47616285 -0.37664127]]\n","Ação tomada: left\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zKubMlQ_n3JK","colab_type":"text"},"source":["- **Caso de estudo - Labirinto proposto II (subseção 3.1.2): Apresentação do função Q-valor para 3 estados representativos do ambiente**"]},{"cell_type":"code","metadata":{"id":"iYwy0PaAsAmW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"ok","timestamp":1595182331767,"user_tz":180,"elapsed":6262,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"b66afb81-9c47-4496-8442-53979c6cb908"},"source":["qmaze2.reset(rat_positions2[0][1])\n","show(qmaze2);"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAGXElEQVR4nO3dMW5TaRfH4XM/IVHACIpIFsgFnRdwvYCko8sm0KwgLTswG/hWkF3YC3AKOtJRREJIdJCK4k4RoqFIhkS8L/E/eR7pVkFHR05+jtMchmmaCth9/7vrBYCbESuEECuEECuEECuEECuEeHSbf7y3tze9evWq6QLn5+f14cOHpjOrql68eFEvX75sPvf8/LyePHkSMTdp17S5vXb9+PFjffnyZbjyi9M03fgZx3Fqbb1eT1XV/FmtVs13vdw3ZW7Srmlze+36o7Er+/MxGEKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFULc6mBaL1OH/29ns9k0n5loGK6+vfU7VqtVvXv3rvncw8PD2t/fbz73vhh+FcowDH9X1d9VVbPZbDw+Pm66wLdv3+rp06dNZ5r778zT09OmM6uq5vN5ff36tfnc58+f197eXvO5vV7bHj8HR0dHtd1ur3yH/WWsP1sul9N2u222WNXFb8Ae76bmXsw8ODhoOrPq4jdrj08uh4eH9ebNm+Zze722PX4OlsvltbH6mxVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCOJh2j+f2PJg2m82az017bf/0wbSapunGzziOU2vr9br5THP/nVlVzZ/VatV818t9U+b22vVHY1f252MwhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhLhVrCcnJzUMQ9Onx8zLuT303LfHzOvu+fzOM45j1PfsvrjVdcNnz56Nb9++bbrAfD6vs7OzpjMv5/a4wPf58+du+7ae2/MK4UO/mrjz1w2r06W8XnN76LlvymvgaqLrhsB/ECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEuFWs4zh2uZTXeubl3B4X+Hrty4Wky5F//LX51Q/Kz9cNZ7PZeHx83HSBXlfiel3gWywWXfbtcTUx8brhQ78c2ey64Y/La031uhLX6wJfr31dN+x76TLltXXdEO4BsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUKIR3e9AJmmDhcZN5tNzNzNZtN03k24bnhLrhv2/Z6lzO21q+uGrhs21fN7ljK3166uG8I9IFYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIca8Ppj30uUm7ps11MM3cnZ9pbr+Z0+RgGtwLYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQrhve47k9dz09PW0+dz6f19nZWcTcXrseHR3VNE2uGz60uT13rarmz2q1ipnba9eLJF03hGhihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRA7EeswDM2fk5OTBz+3567X3Qn6nWccx5i5PXe9tpNpB64bPvRLeb3m9tx1Nps1n+ty5MV1w+12u7vXDSvkol3a3J679uBy5DT9aMx1Q0gmVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgghVgjx6K4XqLq4A9XaZrN58HN77trLMFx9K+x3rNfr5jOrqj59+tR85vfv36/92k5cN0y5aJc2N2nXy7k9Ll0uFosur+3jx4+bzqy6uG74/v37K9+xfhnrz5bL5bTdbpstVnXxLr2/v990prn9Zvaee3Bw0Hzuer3u8touFoumM6uqXr9+fW2s/maFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFELc6mFZVi6pqfdFqr6q+NJ5pbr+Z5vabWVW1mKbpr6u+cKuDaT0Mw7Cdpmlpbvu5Sbumzb2LXX0MhhBihRC7EOv/ze02N2nXtLl/fNc7/5sVuJld+M0K3IBYIYRYIYRYIYRYIcQ/VCEb9WEPymQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"A2GojQo7sDrD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1595182398596,"user_tz":180,"elapsed":603,"user":{"displayName":"Guilherme Rosa","photoUrl":"","userId":"00445763470649378773"}},"outputId":"1b6253cb-13c8-4071-9161-a7bfdee5d6c4"},"source":["for i in range(0, 3):\n","    idx, rat_position = random.choice(list(rat_positions2))\n","    print('-------------------------------------------------------------------')\n","    print(f'Posição do rato: {rat_position}')\n","    print(f'Função Q-valor: {q_values2[idx]}')\n","    print(f'Ação tomada: {actions_dict[np.argmax(q_values2[idx])]}')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["-------------------------------------------------------------------\n","Posição do rato: (2, 7)\n","Função Q-valor: [[-0.7811699  -0.7420155  -0.6791441  -0.48888922]]\n","Ação tomada: down\n","-------------------------------------------------------------------\n","Posição do rato: (7, 1)\n","Função Q-valor: [[-0.00362578 -0.53077996 -0.24604756 -0.154458  ]]\n","Ação tomada: left\n","-------------------------------------------------------------------\n","Posição do rato: (8, 6)\n","Função Q-valor: [[ 0.20405135 -0.5634073   0.73469174  0.31996697]]\n","Ação tomada: right\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZN_ds0-YgAla","colab_type":"text"},"source":["#### **3.3. Explique como é definida a função de erro quadrático médio usada no treinamento.**\n"]},{"cell_type":"markdown","metadata":{"id":"ykSzkAbjlbVc","colab_type":"text"},"source":["\n","- Nesse problema de aprendizado por reforço é explorada a técnica *Deep Q-Learning*, que busca aproximar, por meio do treinamento de uma rede neural, uma função Q-valor que satisfaça o Princípio de Otimalidade de Bellman.\n","\n","- A função Q-valor indica a recompensa acumulada esperada quando o agente segue uma política $\\pi$ a partir de um par estado-ação. Portanto, a função Q-valor ótima é aquela que maximiza a recompensa acumulada esperada quando o agente segue uma política $\\pi$ a partir de um par estado-ação.\n","\n","- Para satisfazer o Princípio de Otimalidade de Bellman, a função Q-valor ótima deve satisfazer a Equação de Bellman, apresentada a seguir:\n","\n","$$\n","Q^{*}(s, a) = \\mathbb{E}[r + \\gamma\\max_{a'}Q^{*}(s', a')|s, a]\n","$$\n","\n","onde $(s,a)$ é o par estado-ação no instante atual e $(s', a')$ é o par estado-ação no instante seguinte. Logo, a equação de Belmman é recursiva e, quando satisfeita, faz com que o agente tome para cada estado a ação que maximiza a recompensa acumulada esperada.\n","\n","- Para obter uma aproximação da função Q-valor, o treinamento da rede neural tem como objetivo fazer com que os lados direito e esquerdo da equação de Belmman sejam iguais, isto é:\n","\n","$$\n","Q^{*}(s, a) \\approx \\mathbb{E}[r + \\gamma\\max_{a'}Q^{*}(s', a')|s, a]\n","$$\n","$$\n","\\mathbb{E}[r + \\gamma\\max_{a'}Q^{*}(s', a')|s, a] - Q^{*}(s, a) \\approx 0\n","$$\n","\n","- Minimizar a diferença (o erro) entre os dois lados da equação pode ser feita com o uso da função erro quadrático médio como função custo:\n","$$\n","L_i(\\theta_i) = \\mathbb{E}[(\\mathbb{E}[r + \\gamma\\max_{a'}Q^{*}(s', a', \\theta_{i-1})|s, a] - Q^{*}(s, a, \\theta_i))^2]]\n","$$\n","\n","- O termo $\\mathbb{E}[r + \\gamma\\max_{a'}Q^{*}(s', a', \\theta_{i-1})|s, a]$ pode ser visto como a saída desejada, enquanto o termo $Q^{*}(s, a, \\theta_i)$ pode ser visto como a saída predita pelo modelo.\n","\n","- O código que implementa as saídas desejadas é apresentado abaixo.\n","\n","```\n","inputs = np.zeros((data_size, env_size))\n","targets = np.zeros((data_size, self.num_actions))\n","for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n","\n","    envstate, action, reward, envstate_next, game_over = self.memory[j]\n","    inputs[i] = envstate\n","    # There should be no target values for actions not taken.\n","    targets[i] = self.predict(envstate)\n","    # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n","    Q_sa = np.max(self.predict(envstate_next))\n","    if game_over:\n","        targets[i, action] = reward\n","    else:\n","        # reward + gamma * max_a' Q(s', a')\n","        targets[i, action] = reward + self.discount * Q_sa\n","```\n","\n","- O erro quadrático médio é tomado entre a função Q-valor predita pela rede e a função contida na variável *target*.\n","\n","- É importante destacar que os valores da função Q-valor predita pela rede para as ações que não foram tomadas são iguais tanto no estado atual quanto no estado seguinte. Dessa forma, quando o erro quadrático médio é calculado, o erro referente à esses elementos é nulo."]},{"cell_type":"markdown","metadata":{"id":"c2E6GfuzgHMe","colab_type":"text"},"source":["#### **3.4. Explique como é trabalhada a técnica de *experience replay*.**"]},{"cell_type":"markdown","metadata":{"id":"unUH4xk5zsUN","colab_type":"text"},"source":["- A técnica de *experience replay* é utilizada no treinamento da rede neural. \n","\n","- Esta técnica utiliza a variável *episode*, que é uma tupla de 5 elementos criada após uma ação do agente e que contém:\n","  - *envstate*: estado atual do ambiente\n","  - *action*: ação tomada pelo agente\n","  - *reward*: ação recebida pelo agente após realizar a ação *action*\n","  - *envstate_next*: estado seguinte do ambiente após a ação ser tomada\n","  - *game_over*: variável que indica se o jogo terminou (com vitória ou derrota)\n","\n","- Uma época de treinamento do modelo começa com o rato na posição inicial e termina com uma vitória ou derrota.\n","\n","- Enquanto o jogo (época) não termina:\n","\n","  - O agente toma uma ação (exploratória ou explotatória), cria um episódio e salva na memória.\n","\n","    - O tamanho da memória representa o número máximo de episódios armazenados. Se o número máximo é atingido, o episódio mais antigo é removido e o novo episódio é integrado à memória.\n","\n","  - O modelo é treinado com um conjunto aleatório de episódios armazenados da memória (*batch*), conforme apresentado na seção 3.3 (*experience replay*).\n","\n","- Portanto, em cada época de treinamento, o modelo é treinado com vários conjuntos de episódios já vivenciados pelo agente tanto naquela época quanto em épocas anteriores."]}]}